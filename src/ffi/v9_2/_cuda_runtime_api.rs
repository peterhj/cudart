/* automatically generated by rust-bindgen */

extern "C" { # [ doc = " \\brief Destroy all allocations and reset all state on the current device" ] # [ doc = " in the current process." ] # [ doc = "" ] # [ doc = " Explicitly destroys and cleans up all resources associated with the current" ] # [ doc = " device in the current process.  Any subsequent API call to this device will" ] # [ doc = " reinitialize the device." ] # [ doc = "" ] # [ doc = " Note that this function will reset the device immediately.  It is the caller\'s" ] # [ doc = " responsibility to ensure that the device is not being accessed by any" ] # [ doc = " other host threads from the process when this function is called." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaDeviceSynchronize" ] pub fn cudaDeviceReset ( ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Wait for compute device to finish" ] # [ doc = "" ] # [ doc = " Blocks until the device has completed all preceding requested tasks." ] # [ doc = " ::cudaDeviceSynchronize() returns an error if one of the preceding tasks" ] # [ doc = " has failed. If the ::cudaDeviceScheduleBlockingSync flag was set for" ] # [ doc = " this device, the host thread will block until the device has finished" ] # [ doc = " its work." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaDeviceReset," ] # [ doc = " ::cuCtxSynchronize" ] pub fn cudaDeviceSynchronize ( ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Returns the description string for an error code" ] # [ doc = "" ] # [ doc = " Returns the description string for an error code.  If the error" ] # [ doc = " code is not recognized, \"unrecognized error code\" is returned." ] # [ doc = "" ] # [ doc = " \\param error - Error code to convert to string" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " \\p char* pointer to a NULL-terminated string" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetErrorName, ::cudaGetLastError, ::cudaPeekAtLastError, ::cudaError," ] # [ doc = " ::cuGetErrorString" ] pub fn cudaGetErrorString ( error : cudaError_t ) -> * const :: std :: os :: raw :: c_char ; } extern "C" { # [ doc = " \\brief Returns the number of compute-capable devices" ] # [ doc = "" ] # [ doc = " Returns in \\p *count the number of devices with compute capability greater" ] # [ doc = " or equal to 2.0 that are available for execution.  If there is no such" ] # [ doc = " device then ::cudaGetDeviceCount() will return ::cudaErrorNoDevice." ] # [ doc = " If no driver can be loaded to determine if any such devices exist then" ] # [ doc = " ::cudaGetDeviceCount() will return ::cudaErrorInsufficientDriver." ] # [ doc = "" ] # [ doc = " \\param count - Returns the number of devices with compute capability" ] # [ doc = " greater or equal to 2.0" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorNoDevice," ] # [ doc = " ::cudaErrorInsufficientDriver" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetDevice, ::cudaSetDevice, ::cudaGetDeviceProperties," ] # [ doc = " ::cudaChooseDevice," ] # [ doc = " ::cuDeviceGetCount" ] pub fn cudaGetDeviceCount ( count : * mut :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Returns information about the compute-device" ] # [ doc = "" ] # [ doc = " Returns in \\p *prop the properties of device \\p dev. The ::cudaDeviceProp" ] # [ doc = " structure is defined as:" ] # [ doc = " \\code" ] # [ doc = "struct cudaDeviceProp {" ] # [ doc = "char name[256];" ] # [ doc = "size_t totalGlobalMem;" ] # [ doc = "size_t sharedMemPerBlock;" ] # [ doc = "int regsPerBlock;" ] # [ doc = "int warpSize;" ] # [ doc = "size_t memPitch;" ] # [ doc = "int maxThreadsPerBlock;" ] # [ doc = "int maxThreadsDim[3];" ] # [ doc = "int maxGridSize[3];" ] # [ doc = "int clockRate;" ] # [ doc = "size_t totalConstMem;" ] # [ doc = "int major;" ] # [ doc = "int minor;" ] # [ doc = "size_t textureAlignment;" ] # [ doc = "size_t texturePitchAlignment;" ] # [ doc = "int deviceOverlap;" ] # [ doc = "int multiProcessorCount;" ] # [ doc = "int kernelExecTimeoutEnabled;" ] # [ doc = "int integrated;" ] # [ doc = "int canMapHostMemory;" ] # [ doc = "int computeMode;" ] # [ doc = "int maxTexture1D;" ] # [ doc = "int maxTexture1DMipmap;" ] # [ doc = "int maxTexture1DLinear;" ] # [ doc = "int maxTexture2D[2];" ] # [ doc = "int maxTexture2DMipmap[2];" ] # [ doc = "int maxTexture2DLinear[3];" ] # [ doc = "int maxTexture2DGather[2];" ] # [ doc = "int maxTexture3D[3];" ] # [ doc = "int maxTexture3DAlt[3];" ] # [ doc = "int maxTextureCubemap;" ] # [ doc = "int maxTexture1DLayered[2];" ] # [ doc = "int maxTexture2DLayered[3];" ] # [ doc = "int maxTextureCubemapLayered[2];" ] # [ doc = "int maxSurface1D;" ] # [ doc = "int maxSurface2D[2];" ] # [ doc = "int maxSurface3D[3];" ] # [ doc = "int maxSurface1DLayered[2];" ] # [ doc = "int maxSurface2DLayered[3];" ] # [ doc = "int maxSurfaceCubemap;" ] # [ doc = "int maxSurfaceCubemapLayered[2];" ] # [ doc = "size_t surfaceAlignment;" ] # [ doc = "int concurrentKernels;" ] # [ doc = "int ECCEnabled;" ] # [ doc = "int pciBusID;" ] # [ doc = "int pciDeviceID;" ] # [ doc = "int pciDomainID;" ] # [ doc = "int tccDriver;" ] # [ doc = "int asyncEngineCount;" ] # [ doc = "int unifiedAddressing;" ] # [ doc = "int memoryClockRate;" ] # [ doc = "int memoryBusWidth;" ] # [ doc = "int l2CacheSize;" ] # [ doc = "int maxThreadsPerMultiProcessor;" ] # [ doc = "int streamPrioritiesSupported;" ] # [ doc = "int globalL1CacheSupported;" ] # [ doc = "int localL1CacheSupported;" ] # [ doc = "size_t sharedMemPerMultiprocessor;" ] # [ doc = "int regsPerMultiprocessor;" ] # [ doc = "int managedMemory;" ] # [ doc = "int isMultiGpuBoard;" ] # [ doc = "int multiGpuBoardGroupID;" ] # [ doc = "int singleToDoublePrecisionPerfRatio;" ] # [ doc = "int pageableMemoryAccess;" ] # [ doc = "int concurrentManagedAccess;" ] # [ doc = "int computePreemptionSupported;" ] # [ doc = "int canUseHostPointerForRegisteredMem;" ] # [ doc = "int cooperativeLaunch;" ] # [ doc = "int cooperativeMultiDeviceLaunch;" ] # [ doc = "int pageableMemoryAccessUsesHostPageTables;" ] # [ doc = "int directManagedMemAccessFromHost;" ] # [ doc = "}" ] # [ doc = "\\endcode" ] # [ doc = " where:" ] # [ doc = " - \\ref ::cudaDeviceProp::name \"name[256]\" is an ASCII string identifying" ] # [ doc = "   the device;" ] # [ doc = " - \\ref ::cudaDeviceProp::totalGlobalMem \"totalGlobalMem\" is the total" ] # [ doc = "   amount of global memory available on the device in bytes;" ] # [ doc = " - \\ref ::cudaDeviceProp::sharedMemPerBlock \"sharedMemPerBlock\" is the" ] # [ doc = "   maximum amount of shared memory available to a thread block in bytes;" ] # [ doc = " - \\ref ::cudaDeviceProp::regsPerBlock \"regsPerBlock\" is the maximum number" ] # [ doc = "   of 32-bit registers available to a thread block;" ] # [ doc = " - \\ref ::cudaDeviceProp::warpSize \"warpSize\" is the warp size in threads;" ] # [ doc = " - \\ref ::cudaDeviceProp::memPitch \"memPitch\" is the maximum pitch in" ] # [ doc = "   bytes allowed by the memory copy functions that involve memory regions" ] # [ doc = "   allocated through ::cudaMallocPitch();" ] # [ doc = " - \\ref ::cudaDeviceProp::maxThreadsPerBlock \"maxThreadsPerBlock\" is the" ] # [ doc = "   maximum number of threads per block;" ] # [ doc = " - \\ref ::cudaDeviceProp::maxThreadsDim \"maxThreadsDim[3]\" contains the" ] # [ doc = "   maximum size of each dimension of a block;" ] # [ doc = " - \\ref ::cudaDeviceProp::maxGridSize \"maxGridSize[3]\" contains the" ] # [ doc = "   maximum size of each dimension of a grid;" ] # [ doc = " - \\ref ::cudaDeviceProp::clockRate \"clockRate\" is the clock frequency in" ] # [ doc = "   kilohertz;" ] # [ doc = " - \\ref ::cudaDeviceProp::totalConstMem \"totalConstMem\" is the total amount" ] # [ doc = "   of constant memory available on the device in bytes;" ] # [ doc = " - \\ref ::cudaDeviceProp::major \"major\"," ] # [ doc = "   \\ref ::cudaDeviceProp::minor \"minor\" are the major and minor revision" ] # [ doc = "   numbers defining the device\'s compute capability;" ] # [ doc = " - \\ref ::cudaDeviceProp::textureAlignment \"textureAlignment\" is the" ] # [ doc = "   alignment requirement; texture base addresses that are aligned to" ] # [ doc = "   \\ref ::cudaDeviceProp::textureAlignment \"textureAlignment\" bytes do not" ] # [ doc = "   need an offset applied to texture fetches;" ] # [ doc = " - \\ref ::cudaDeviceProp::texturePitchAlignment \"texturePitchAlignment\" is the" ] # [ doc = "   pitch alignment requirement for 2D texture references that are bound to" ] # [ doc = "   pitched memory;" ] # [ doc = " - \\ref ::cudaDeviceProp::deviceOverlap \"deviceOverlap\" is 1 if the device" ] # [ doc = "   can concurrently copy memory between host and device while executing a" ] # [ doc = "   kernel, or 0 if not.  Deprecated, use instead asyncEngineCount." ] # [ doc = " - \\ref ::cudaDeviceProp::multiProcessorCount \"multiProcessorCount\" is the" ] # [ doc = "   number of multiprocessors on the device;" ] # [ doc = " - \\ref ::cudaDeviceProp::kernelExecTimeoutEnabled \"kernelExecTimeoutEnabled\"" ] # [ doc = "   is 1 if there is a run time limit for kernels executed on the device, or" ] # [ doc = "   0 if not." ] # [ doc = " - \\ref ::cudaDeviceProp::integrated \"integrated\" is 1 if the device is an" ] # [ doc = "   integrated (motherboard) GPU and 0 if it is a discrete (card) component." ] # [ doc = " - \\ref ::cudaDeviceProp::canMapHostMemory \"canMapHostMemory\" is 1 if the" ] # [ doc = "   device can map host memory into the CUDA address space for use with" ] # [ doc = "   ::cudaHostAlloc()/::cudaHostGetDevicePointer(), or 0 if not;" ] # [ doc = " - \\ref ::cudaDeviceProp::computeMode \"computeMode\" is the compute mode" ] # [ doc = "   that the device is currently in. Available modes are as follows:" ] # [ doc = "   - cudaComputeModeDefault: Default mode - Device is not restricted and" ] # [ doc = "     multiple threads can use ::cudaSetDevice() with this device." ] # [ doc = "   - cudaComputeModeExclusive: Compute-exclusive mode - Only one thread will" ] # [ doc = "     be able to use ::cudaSetDevice() with this device." ] # [ doc = "   - cudaComputeModeProhibited: Compute-prohibited mode - No threads can use" ] # [ doc = "     ::cudaSetDevice() with this device." ] # [ doc = "   - cudaComputeModeExclusiveProcess: Compute-exclusive-process mode - Many" ] # [ doc = "     threads in one process will be able to use ::cudaSetDevice() with this device." ] # [ doc = "   <br> If ::cudaSetDevice() is called on an already occupied \\p device with" ] # [ doc = "   computeMode ::cudaComputeModeExclusive, ::cudaErrorDeviceAlreadyInUse" ] # [ doc = "   will be immediately returned indicating the device cannot be used." ] # [ doc = "   When an occupied exclusive mode device is chosen with ::cudaSetDevice," ] # [ doc = "   all subsequent non-device management runtime functions will return" ] # [ doc = "   ::cudaErrorDevicesUnavailable." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture1D \"maxTexture1D\" is the maximum 1D" ] # [ doc = "   texture size." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture1DMipmap \"maxTexture1DMipmap\" is the maximum" ] # [ doc = "   1D mipmapped texture texture size." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture1DLinear \"maxTexture1DLinear\" is the maximum" ] # [ doc = "   1D texture size for textures bound to linear memory." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture2D \"maxTexture2D[2]\" contains the maximum" ] # [ doc = "   2D texture dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture2DMipmap \"maxTexture2DMipmap[2]\" contains the" ] # [ doc = "   maximum 2D mipmapped texture dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture2DLinear \"maxTexture2DLinear[3]\" contains the" ] # [ doc = "   maximum 2D texture dimensions for 2D textures bound to pitch linear memory." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture2DGather \"maxTexture2DGather[2]\" contains the" ] # [ doc = "   maximum 2D texture dimensions if texture gather operations have to be performed." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture3D \"maxTexture3D[3]\" contains the maximum" ] # [ doc = "   3D texture dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture3DAlt \"maxTexture3DAlt[3]\"" ] # [ doc = "   contains the maximum alternate 3D texture dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTextureCubemap \"maxTextureCubemap\" is the" ] # [ doc = "   maximum cubemap texture width or height." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture1DLayered \"maxTexture1DLayered[2]\" contains" ] # [ doc = "   the maximum 1D layered texture dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTexture2DLayered \"maxTexture2DLayered[3]\" contains" ] # [ doc = "   the maximum 2D layered texture dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxTextureCubemapLayered \"maxTextureCubemapLayered[2]\"" ] # [ doc = "   contains the maximum cubemap layered texture dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxSurface1D \"maxSurface1D\" is the maximum 1D" ] # [ doc = "   surface size." ] # [ doc = " - \\ref ::cudaDeviceProp::maxSurface2D \"maxSurface2D[2]\" contains the maximum" ] # [ doc = "   2D surface dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxSurface3D \"maxSurface3D[3]\" contains the maximum" ] # [ doc = "   3D surface dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxSurface1DLayered \"maxSurface1DLayered[2]\" contains" ] # [ doc = "   the maximum 1D layered surface dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxSurface2DLayered \"maxSurface2DLayered[3]\" contains" ] # [ doc = "   the maximum 2D layered surface dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::maxSurfaceCubemap \"maxSurfaceCubemap\" is the maximum" ] # [ doc = "   cubemap surface width or height." ] # [ doc = " - \\ref ::cudaDeviceProp::maxSurfaceCubemapLayered \"maxSurfaceCubemapLayered[2]\"" ] # [ doc = "   contains the maximum cubemap layered surface dimensions." ] # [ doc = " - \\ref ::cudaDeviceProp::surfaceAlignment \"surfaceAlignment\" specifies the" ] # [ doc = "   alignment requirements for surfaces." ] # [ doc = " - \\ref ::cudaDeviceProp::concurrentKernels \"concurrentKernels\" is 1 if the" ] # [ doc = "   device supports executing multiple kernels within the same context" ] # [ doc = "   simultaneously, or 0 if not. It is not guaranteed that multiple kernels" ] # [ doc = "   will be resident on the device concurrently so this feature should not be" ] # [ doc = "   relied upon for correctness;" ] # [ doc = " - \\ref ::cudaDeviceProp::ECCEnabled \"ECCEnabled\" is 1 if the device has ECC" ] # [ doc = "   support turned on, or 0 if not." ] # [ doc = " - \\ref ::cudaDeviceProp::pciBusID \"pciBusID\" is the PCI bus identifier of" ] # [ doc = "   the device." ] # [ doc = " - \\ref ::cudaDeviceProp::pciDeviceID \"pciDeviceID\" is the PCI device" ] # [ doc = "   (sometimes called slot) identifier of the device." ] # [ doc = " - \\ref ::cudaDeviceProp::pciDomainID \"pciDomainID\" is the PCI domain identifier" ] # [ doc = "   of the device." ] # [ doc = " - \\ref ::cudaDeviceProp::tccDriver \"tccDriver\" is 1 if the device is using a" ] # [ doc = "   TCC driver or 0 if not." ] # [ doc = " - \\ref ::cudaDeviceProp::asyncEngineCount \"asyncEngineCount\" is 1 when the" ] # [ doc = "   device can concurrently copy memory between host and device while executing" ] # [ doc = "   a kernel. It is 2 when the device can concurrently copy memory between host" ] # [ doc = "   and device in both directions and execute a kernel at the same time. It is" ] # [ doc = "   0 if neither of these is supported." ] # [ doc = " - \\ref ::cudaDeviceProp::unifiedAddressing \"unifiedAddressing\" is 1 if the device" ] # [ doc = "   shares a unified address space with the host and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::memoryClockRate \"memoryClockRate\" is the peak memory" ] # [ doc = "   clock frequency in kilohertz." ] # [ doc = " - \\ref ::cudaDeviceProp::memoryBusWidth \"memoryBusWidth\" is the memory bus width" ] # [ doc = "   in bits." ] # [ doc = " - \\ref ::cudaDeviceProp::l2CacheSize \"l2CacheSize\" is L2 cache size in bytes." ] # [ doc = " - \\ref ::cudaDeviceProp::maxThreadsPerMultiProcessor \"maxThreadsPerMultiProcessor\"" ] # [ doc = "   is the number of maximum resident threads per multiprocessor." ] # [ doc = " - \\ref ::cudaDeviceProp::streamPrioritiesSupported \"streamPrioritiesSupported\"" ] # [ doc = "   is 1 if the device supports stream priorities, or 0 if it is not supported." ] # [ doc = " - \\ref ::cudaDeviceProp::globalL1CacheSupported \"globalL1CacheSupported\"" ] # [ doc = "   is 1 if the device supports caching of globals in L1 cache, or 0 if it is not supported." ] # [ doc = " - \\ref ::cudaDeviceProp::localL1CacheSupported \"localL1CacheSupported\"" ] # [ doc = "   is 1 if the device supports caching of locals in L1 cache, or 0 if it is not supported." ] # [ doc = " - \\ref ::cudaDeviceProp::sharedMemPerMultiprocessor \"sharedMemPerMultiprocessor\" is the" ] # [ doc = "   maximum amount of shared memory available to a multiprocessor in bytes; this amount is" ] # [ doc = "   shared by all thread blocks simultaneously resident on a multiprocessor;" ] # [ doc = " - \\ref ::cudaDeviceProp::regsPerMultiprocessor \"regsPerMultiprocessor\" is the maximum number" ] # [ doc = "   of 32-bit registers available to a multiprocessor; this number is shared" ] # [ doc = "   by all thread blocks simultaneously resident on a multiprocessor;" ] # [ doc = " - \\ref ::cudaDeviceProp::managedMemory \"managedMemory\"" ] # [ doc = "   is 1 if the device supports allocating managed memory on this system, or 0 if it is not supported." ] # [ doc = " - \\ref ::cudaDeviceProp::isMultiGpuBoard \"isMultiGpuBoard\"" ] # [ doc = "   is 1 if the device is on a multi-GPU board (e.g. Gemini cards), and 0 if not;" ] # [ doc = " - \\ref ::cudaDeviceProp::multiGpuBoardGroupID \"multiGpuBoardGroupID\" is a unique identifier" ] # [ doc = "   for a group of devices associated with the same board." ] # [ doc = "   Devices on the same multi-GPU board will share the same identifier;" ] # [ doc = " - \\ref ::cudaDeviceProp::singleToDoublePrecisionPerfRatio \"singleToDoublePrecisionPerfRatio\"" ] # [ doc = "   is the ratio of single precision performance (in floating-point operations per second)" ] # [ doc = "   to double precision performance." ] # [ doc = " - \\ref ::cudaDeviceProp::pageableMemoryAccess \"pageableMemoryAccess\" is 1 if the device supports" ] # [ doc = "   coherently accessing pageable memory without calling cudaHostRegister on it, and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::concurrentManagedAccess \"concurrentManagedAccess\" is 1 if the device can" ] # [ doc = "   coherently access managed memory concurrently with the CPU, and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::computePreemptionSupported \"computePreemptionSupported\" is 1 if the device" ] # [ doc = "   supports Compute Preemption, and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::canUseHostPointerForRegisteredMem \"canUseHostPointerForRegisteredMem\" is 1 if" ] # [ doc = "   the device can access host registered memory at the same virtual address as the CPU, and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::cooperativeLaunch \"cooperativeLaunch\" is 1 if the device supports launching" ] # [ doc = "   cooperative kernels via ::cudaLaunchCooperativeKernel, and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::cooperativeMultiDeviceLaunch \"cooperativeMultiDeviceLaunch\" is 1 if the device" ] # [ doc = "   supports launching cooperative kernels via ::cudaLaunchCooperativeKernelMultiDevice, and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::pageableMemoryAccessUsesHostPageTables \"pageableMemoryAccessUsesHostPageTables\" is 1 if the device accesses" ] # [ doc = "   pageable memory via the host\'s page tables, and 0 otherwise." ] # [ doc = " - \\ref ::cudaDeviceProp::directManagedMemAccessFromHost \"directManagedMemAccessFromHost\" is 1 if the host can directly access managed" ] # [ doc = "   memory on the device without migration, and 0 otherwise." ] # [ doc = "" ] # [ doc = " \\param prop   - Properties for the specified device" ] # [ doc = " \\param device - Device number to get properties for" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetDeviceCount, ::cudaGetDevice, ::cudaSetDevice, ::cudaChooseDevice," ] # [ doc = " ::cudaDeviceGetAttribute," ] # [ doc = " ::cuDeviceGetAttribute," ] # [ doc = " ::cuDeviceGetName" ] pub fn cudaGetDeviceProperties ( prop : * mut cudaDeviceProp , device : :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Returns information about the device" ] # [ doc = "" ] # [ doc = " Returns in \\p *value the integer value of the attribute \\p attr on device" ] # [ doc = " \\p device. The supported attributes are:" ] # [ doc = " - ::cudaDevAttrMaxThreadsPerBlock: Maximum number of threads per block;" ] # [ doc = " - ::cudaDevAttrMaxBlockDimX: Maximum x-dimension of a block;" ] # [ doc = " - ::cudaDevAttrMaxBlockDimY: Maximum y-dimension of a block;" ] # [ doc = " - ::cudaDevAttrMaxBlockDimZ: Maximum z-dimension of a block;" ] # [ doc = " - ::cudaDevAttrMaxGridDimX: Maximum x-dimension of a grid;" ] # [ doc = " - ::cudaDevAttrMaxGridDimY: Maximum y-dimension of a grid;" ] # [ doc = " - ::cudaDevAttrMaxGridDimZ: Maximum z-dimension of a grid;" ] # [ doc = " - ::cudaDevAttrMaxSharedMemoryPerBlock: Maximum amount of shared memory" ] # [ doc = "   available to a thread block in bytes;" ] # [ doc = " - ::cudaDevAttrTotalConstantMemory: Memory available on device for" ] # [ doc = "   __constant__ variables in a CUDA C kernel in bytes;" ] # [ doc = " - ::cudaDevAttrWarpSize: Warp size in threads;" ] # [ doc = " - ::cudaDevAttrMaxPitch: Maximum pitch in bytes allowed by the memory copy" ] # [ doc = "   functions that involve memory regions allocated through ::cudaMallocPitch();" ] # [ doc = " - ::cudaDevAttrMaxTexture1DWidth: Maximum 1D texture width;" ] # [ doc = " - ::cudaDevAttrMaxTexture1DLinearWidth: Maximum width for a 1D texture bound" ] # [ doc = "   to linear memory;" ] # [ doc = " - ::cudaDevAttrMaxTexture1DMipmappedWidth: Maximum mipmapped 1D texture width;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DWidth: Maximum 2D texture width;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DHeight: Maximum 2D texture height;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DLinearWidth: Maximum width for a 2D texture" ] # [ doc = "   bound to linear memory;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DLinearHeight: Maximum height for a 2D texture" ] # [ doc = "   bound to linear memory;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DLinearPitch: Maximum pitch in bytes for a 2D" ] # [ doc = "   texture bound to linear memory;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DMipmappedWidth: Maximum mipmapped 2D texture" ] # [ doc = "   width;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DMipmappedHeight: Maximum mipmapped 2D texture" ] # [ doc = "   height;" ] # [ doc = " - ::cudaDevAttrMaxTexture3DWidth: Maximum 3D texture width;" ] # [ doc = " - ::cudaDevAttrMaxTexture3DHeight: Maximum 3D texture height;" ] # [ doc = " - ::cudaDevAttrMaxTexture3DDepth: Maximum 3D texture depth;" ] # [ doc = " - ::cudaDevAttrMaxTexture3DWidthAlt: Alternate maximum 3D texture width," ] # [ doc = "   0 if no alternate maximum 3D texture size is supported;" ] # [ doc = " - ::cudaDevAttrMaxTexture3DHeightAlt: Alternate maximum 3D texture height," ] # [ doc = "   0 if no alternate maximum 3D texture size is supported;" ] # [ doc = " - ::cudaDevAttrMaxTexture3DDepthAlt: Alternate maximum 3D texture depth," ] # [ doc = "   0 if no alternate maximum 3D texture size is supported;" ] # [ doc = " - ::cudaDevAttrMaxTextureCubemapWidth: Maximum cubemap texture width or" ] # [ doc = "   height;" ] # [ doc = " - ::cudaDevAttrMaxTexture1DLayeredWidth: Maximum 1D layered texture width;" ] # [ doc = " - ::cudaDevAttrMaxTexture1DLayeredLayers: Maximum layers in a 1D layered" ] # [ doc = "   texture;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DLayeredWidth: Maximum 2D layered texture width;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DLayeredHeight: Maximum 2D layered texture height;" ] # [ doc = " - ::cudaDevAttrMaxTexture2DLayeredLayers: Maximum layers in a 2D layered" ] # [ doc = "   texture;" ] # [ doc = " - ::cudaDevAttrMaxTextureCubemapLayeredWidth: Maximum cubemap layered" ] # [ doc = "   texture width or height;" ] # [ doc = " - ::cudaDevAttrMaxTextureCubemapLayeredLayers: Maximum layers in a cubemap" ] # [ doc = "   layered texture;" ] # [ doc = " - ::cudaDevAttrMaxSurface1DWidth: Maximum 1D surface width;" ] # [ doc = " - ::cudaDevAttrMaxSurface2DWidth: Maximum 2D surface width;" ] # [ doc = " - ::cudaDevAttrMaxSurface2DHeight: Maximum 2D surface height;" ] # [ doc = " - ::cudaDevAttrMaxSurface3DWidth: Maximum 3D surface width;" ] # [ doc = " - ::cudaDevAttrMaxSurface3DHeight: Maximum 3D surface height;" ] # [ doc = " - ::cudaDevAttrMaxSurface3DDepth: Maximum 3D surface depth;" ] # [ doc = " - ::cudaDevAttrMaxSurface1DLayeredWidth: Maximum 1D layered surface width;" ] # [ doc = " - ::cudaDevAttrMaxSurface1DLayeredLayers: Maximum layers in a 1D layered" ] # [ doc = "   surface;" ] # [ doc = " - ::cudaDevAttrMaxSurface2DLayeredWidth: Maximum 2D layered surface width;" ] # [ doc = " - ::cudaDevAttrMaxSurface2DLayeredHeight: Maximum 2D layered surface height;" ] # [ doc = " - ::cudaDevAttrMaxSurface2DLayeredLayers: Maximum layers in a 2D layered" ] # [ doc = "   surface;" ] # [ doc = " - ::cudaDevAttrMaxSurfaceCubemapWidth: Maximum cubemap surface width;" ] # [ doc = " - ::cudaDevAttrMaxSurfaceCubemapLayeredWidth: Maximum cubemap layered" ] # [ doc = "   surface width;" ] # [ doc = " - ::cudaDevAttrMaxSurfaceCubemapLayeredLayers: Maximum layers in a cubemap" ] # [ doc = "   layered surface;" ] # [ doc = " - ::cudaDevAttrMaxRegistersPerBlock: Maximum number of 32-bit registers" ] # [ doc = "   available to a thread block;" ] # [ doc = " - ::cudaDevAttrClockRate: Peak clock frequency in kilohertz;" ] # [ doc = " - ::cudaDevAttrTextureAlignment: Alignment requirement; texture base" ] # [ doc = "   addresses aligned to ::textureAlign bytes do not need an offset applied" ] # [ doc = "   to texture fetches;" ] # [ doc = " - ::cudaDevAttrTexturePitchAlignment: Pitch alignment requirement for 2D" ] # [ doc = "   texture references bound to pitched memory;" ] # [ doc = " - ::cudaDevAttrGpuOverlap: 1 if the device can concurrently copy memory" ] # [ doc = "   between host and device while executing a kernel, or 0 if not;" ] # [ doc = " - ::cudaDevAttrMultiProcessorCount: Number of multiprocessors on the device;" ] # [ doc = " - ::cudaDevAttrKernelExecTimeout: 1 if there is a run time limit for kernels" ] # [ doc = "   executed on the device, or 0 if not;" ] # [ doc = " - ::cudaDevAttrIntegrated: 1 if the device is integrated with the memory" ] # [ doc = "   subsystem, or 0 if not;" ] # [ doc = " - ::cudaDevAttrCanMapHostMemory: 1 if the device can map host memory into" ] # [ doc = "   the CUDA address space, or 0 if not;" ] # [ doc = " - ::cudaDevAttrComputeMode: Compute mode is the compute mode that the device" ] # [ doc = "   is currently in. Available modes are as follows:" ] # [ doc = "   - ::cudaComputeModeDefault: Default mode - Device is not restricted and" ] # [ doc = "     multiple threads can use ::cudaSetDevice() with this device." ] # [ doc = "   - ::cudaComputeModeExclusive: Compute-exclusive mode - Only one thread will" ] # [ doc = "     be able to use ::cudaSetDevice() with this device." ] # [ doc = "   - ::cudaComputeModeProhibited: Compute-prohibited mode - No threads can use" ] # [ doc = "     ::cudaSetDevice() with this device." ] # [ doc = "   - ::cudaComputeModeExclusiveProcess: Compute-exclusive-process mode - Many" ] # [ doc = "     threads in one process will be able to use ::cudaSetDevice() with this" ] # [ doc = "     device." ] # [ doc = " - ::cudaDevAttrConcurrentKernels: 1 if the device supports executing" ] # [ doc = "   multiple kernels within the same context simultaneously, or 0 if" ] # [ doc = "   not. It is not guaranteed that multiple kernels will be resident on the" ] # [ doc = "   device concurrently so this feature should not be relied upon for" ] # [ doc = "   correctness;" ] # [ doc = " - ::cudaDevAttrEccEnabled: 1 if error correction is enabled on the device," ] # [ doc = "   0 if error correction is disabled or not supported by the device;" ] # [ doc = " - ::cudaDevAttrPciBusId: PCI bus identifier of the device;" ] # [ doc = " - ::cudaDevAttrPciDeviceId: PCI device (also known as slot) identifier of" ] # [ doc = "   the device;" ] # [ doc = " - ::cudaDevAttrTccDriver: 1 if the device is using a TCC driver. TCC is only" ] # [ doc = "   available on Tesla hardware running Windows Vista or later;" ] # [ doc = " - ::cudaDevAttrMemoryClockRate: Peak memory clock frequency in kilohertz;" ] # [ doc = " - ::cudaDevAttrGlobalMemoryBusWidth: Global memory bus width in bits;" ] # [ doc = " - ::cudaDevAttrL2CacheSize: Size of L2 cache in bytes. 0 if the device" ] # [ doc = "   doesn\'t have L2 cache;" ] # [ doc = " - ::cudaDevAttrMaxThreadsPerMultiProcessor: Maximum resident threads per" ] # [ doc = "   multiprocessor;" ] # [ doc = " - ::cudaDevAttrUnifiedAddressing: 1 if the device shares a unified address" ] # [ doc = "   space with the host, or 0 if not;" ] # [ doc = " - ::cudaDevAttrComputeCapabilityMajor: Major compute capability version" ] # [ doc = "   number;" ] # [ doc = " - ::cudaDevAttrComputeCapabilityMinor: Minor compute capability version" ] # [ doc = "   number;" ] # [ doc = " - ::cudaDevAttrStreamPrioritiesSupported: 1 if the device supports stream" ] # [ doc = "   priorities, or 0 if not;" ] # [ doc = " - ::cudaDevAttrGlobalL1CacheSupported: 1 if device supports caching globals" ] # [ doc = "    in L1 cache, 0 if not;" ] # [ doc = " - ::cudaDevAttrLocalL1CacheSupported: 1 if device supports caching locals" ] # [ doc = "    in L1 cache, 0 if not;" ] # [ doc = " - ::cudaDevAttrMaxSharedMemoryPerMultiprocessor: Maximum amount of shared memory" ] # [ doc = "   available to a multiprocessor in bytes; this amount is shared by all" ] # [ doc = "   thread blocks simultaneously resident on a multiprocessor;" ] # [ doc = " - ::cudaDevAttrMaxRegistersPerMultiprocessor: Maximum number of 32-bit registers" ] # [ doc = "   available to a multiprocessor; this number is shared by all thread blocks" ] # [ doc = "   simultaneously resident on a multiprocessor;" ] # [ doc = " - ::cudaDevAttrManagedMemory: 1 if device supports allocating" ] # [ doc = "   managed memory, 0 if not;" ] # [ doc = " - ::cudaDevAttrIsMultiGpuBoard: 1 if device is on a multi-GPU board, 0 if not;" ] # [ doc = " - ::cudaDevAttrMultiGpuBoardGroupID: Unique identifier for a group of devices on the" ] # [ doc = "   same multi-GPU board;" ] # [ doc = " - ::cudaDevAttrHostNativeAtomicSupported: 1 if the link between the device and the" ] # [ doc = "   host supports native atomic operations;" ] # [ doc = " - ::cudaDevAttrSingleToDoublePrecisionPerfRatio: Ratio of single precision performance" ] # [ doc = "   (in floating-point operations per second) to double precision performance;" ] # [ doc = " - ::cudaDevAttrPageableMemoryAccess: 1 if the device supports coherently accessing" ] # [ doc = "   pageable memory without calling cudaHostRegister on it, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrConcurrentManagedAccess: 1 if the device can coherently access managed" ] # [ doc = "   memory concurrently with the CPU, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrComputePreemptionSupported: 1 if the device supports" ] # [ doc = "   Compute Preemption, 0 if not." ] # [ doc = " - ::cudaDevAttrCanUseHostPointerForRegisteredMem: 1 if the device can access host" ] # [ doc = "   registered memory at the same virtual address as the CPU, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrCooperativeLaunch: 1 if the device supports launching cooperative kernels" ] # [ doc = "   via ::cudaLaunchCooperativeKernel, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrCooperativeMultiDeviceLaunch: 1 if the device supports launching cooperative" ] # [ doc = "   kernels via ::cudaLaunchCooperativeKernelMultiDevice, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrCanFlushRemoteWrites: 1 if the device supports flushing of outstanding" ] # [ doc = "   remote writes, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrHostRegisterSupported: 1 if the device supports host memory registration" ] # [ doc = "   via ::cudaHostRegister, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrPageableMemoryAccessUsesHostPageTables: 1 if the device accesses pageable memory via the" ] # [ doc = "   host\'s page tables, and 0 otherwise." ] # [ doc = " - ::cudaDevAttrDirectManagedMemAccessFromHost: 1 if the host can directly access managed memory on the device" ] # [ doc = "   without migration, and 0 otherwise." ] # [ doc = "" ] # [ doc = " \\param value  - Returned device attribute value" ] # [ doc = " \\param attr   - Device attribute to query" ] # [ doc = " \\param device - Device number to query" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidDevice," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetDeviceCount, ::cudaGetDevice, ::cudaSetDevice, ::cudaChooseDevice," ] # [ doc = " ::cudaGetDeviceProperties," ] # [ doc = " ::cuDeviceGetAttribute" ] pub fn cudaDeviceGetAttribute ( value : * mut :: std :: os :: raw :: c_int , attr : cudaDeviceAttr , device : :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Set device to be used for GPU executions" ] # [ doc = "" ] # [ doc = " Sets \\p device as the current device for the calling host thread." ] # [ doc = " Valid device id\'s are 0 to (::cudaGetDeviceCount() - 1)." ] # [ doc = "" ] # [ doc = " Any device memory subsequently allocated from this host thread" ] # [ doc = " using ::cudaMalloc(), ::cudaMallocPitch() or ::cudaMallocArray()" ] # [ doc = " will be physically resident on \\p device.  Any host memory allocated" ] # [ doc = " from this host thread using ::cudaMallocHost() or ::cudaHostAlloc()" ] # [ doc = " or ::cudaHostRegister() will have its lifetime associated  with" ] # [ doc = " \\p device.  Any streams or events created from this host thread will" ] # [ doc = " be associated with \\p device.  Any kernels launched from this host" ] # [ doc = " thread using the <<<>>> operator or ::cudaLaunchKernel() will be executed" ] # [ doc = " on \\p device." ] # [ doc = "" ] # [ doc = " This call may be made from any host thread, to any device, and at" ] # [ doc = " any time.  This function will do no synchronization with the previous" ] # [ doc = " or new device, and should be considered a very low overhead call." ] # [ doc = "" ] # [ doc = " \\param device - Device on which the active host thread should execute the" ] # [ doc = " device code." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidDevice," ] # [ doc = " ::cudaErrorDeviceAlreadyInUse" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetDeviceCount, ::cudaGetDevice, ::cudaGetDeviceProperties," ] # [ doc = " ::cudaChooseDevice," ] # [ doc = " ::cuCtxSetCurrent" ] pub fn cudaSetDevice ( device : :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Returns which device is currently being used" ] # [ doc = "" ] # [ doc = " Returns in \\p *device the current device for the calling host thread." ] # [ doc = "" ] # [ doc = " \\param device - Returns the device on which the active host thread" ] # [ doc = " executes the device code." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetDeviceCount, ::cudaSetDevice, ::cudaGetDeviceProperties," ] # [ doc = " ::cudaChooseDevice," ] # [ doc = " ::cuCtxGetCurrent" ] pub fn cudaGetDevice ( device : * mut :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Sets flags to be used for device executions" ] # [ doc = "" ] # [ doc = " Records \\p flags as the flags to use when initializing the current" ] # [ doc = " device.  If no device has been made current to the calling thread," ] # [ doc = " then \\p flags will be applied to the initialization of any device" ] # [ doc = " initialized by the calling host thread, unless that device has had" ] # [ doc = " its initialization flags set explicitly by this or any host thread." ] # [ doc = "" ] # [ doc = " If the current device has been set and that device has already been" ] # [ doc = " initialized then this call will fail with the error" ] # [ doc = " ::cudaErrorSetOnActiveProcess.  In this case it is necessary" ] # [ doc = " to reset \\p device using ::cudaDeviceReset() before the device\'s" ] # [ doc = " initialization flags may be set." ] # [ doc = "" ] # [ doc = " The two LSBs of the \\p flags parameter can be used to control how the CPU" ] # [ doc = " thread interacts with the OS scheduler when waiting for results from the" ] # [ doc = " device." ] # [ doc = "" ] # [ doc = " - ::cudaDeviceScheduleAuto: The default value if the \\p flags parameter is" ] # [ doc = " zero, uses a heuristic based on the number of active CUDA contexts in the" ] # [ doc = " process \\p C and the number of logical processors in the system \\p P. If" ] # [ doc = " \\p C \\> \\p P, then CUDA will yield to other OS threads when waiting for the" ] # [ doc = " device, otherwise CUDA will not yield while waiting for results and" ] # [ doc = " actively spin on the processor." ] # [ doc = " - ::cudaDeviceScheduleSpin: Instruct CUDA to actively spin when waiting for" ] # [ doc = " results from the device. This can decrease latency when waiting for the" ] # [ doc = " device, but may lower the performance of CPU threads if they are performing" ] # [ doc = " work in parallel with the CUDA thread." ] # [ doc = " - ::cudaDeviceScheduleYield: Instruct CUDA to yield its thread when waiting" ] # [ doc = " for results from the device. This can increase latency when waiting for the" ] # [ doc = " device, but can increase the performance of CPU threads performing work in" ] # [ doc = " parallel with the device." ] # [ doc = " - ::cudaDeviceScheduleBlockingSync: Instruct CUDA to block the CPU thread" ] # [ doc = " on a synchronization primitive when waiting for the device to finish work." ] # [ doc = " - ::cudaDeviceBlockingSync: Instruct CUDA to block the CPU thread on a" ] # [ doc = " synchronization primitive when waiting for the device to finish work. <br>" ] # [ doc = " \\ref deprecated \"Deprecated:\" This flag was deprecated as of CUDA 4.0 and" ] # [ doc = " replaced with ::cudaDeviceScheduleBlockingSync." ] # [ doc = " - ::cudaDeviceMapHost: This flag enables allocating pinned" ] # [ doc = " host memory that is accessible to the device. It is implicit for the" ] # [ doc = " runtime but may be absent if a context is created using the driver API." ] # [ doc = " If this flag is not set, ::cudaHostGetDevicePointer() will always return" ] # [ doc = " a failure code." ] # [ doc = " - ::cudaDeviceLmemResizeToMax: Instruct CUDA to not reduce local memory" ] # [ doc = " after resizing local memory for a kernel. This can prevent thrashing by" ] # [ doc = " local memory allocations when launching many kernels with high local" ] # [ doc = " memory usage at the cost of potentially increased memory usage." ] # [ doc = "" ] # [ doc = " \\param flags - Parameters for device operation" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorSetOnActiveProcess" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetDeviceFlags, ::cudaGetDeviceCount, ::cudaGetDevice, ::cudaGetDeviceProperties," ] # [ doc = " ::cudaSetDevice, ::cudaSetValidDevices," ] # [ doc = " ::cudaChooseDevice," ] # [ doc = " ::cuDevicePrimaryCtxSetFlags" ] pub fn cudaSetDeviceFlags ( flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Gets the flags for the current device" ] # [ doc = "" ] # [ doc = " Returns in \\p flags the flags for the current device.  If there is a" ] # [ doc = " current device for the calling thread, and the device has been initialized" ] # [ doc = " or flags have been set on that device specifically, the flags for the" ] # [ doc = " device are returned.  If there is no current device, but flags have been" ] # [ doc = " set for the thread with ::cudaSetDeviceFlags, the thread flags are returned." ] # [ doc = " Finally, if there is no current device and no thread flags, the flags for" ] # [ doc = " the first device are returned, which may be the default flags.  Compare" ] # [ doc = " to the behavior of ::cudaSetDeviceFlags." ] # [ doc = "" ] # [ doc = " Typically, the flags returned should match the behavior that will be seen" ] # [ doc = " if the calling thread uses a device after this call, without any change to" ] # [ doc = " the flags or current device inbetween by this or another thread.  Note that" ] # [ doc = " if the device is not initialized, it is possible for another thread to" ] # [ doc = " change the flags for the current device before it is initialized." ] # [ doc = " Additionally, when using exclusive mode, if this thread has not requested a" ] # [ doc = " specific device, it may use a device other than the first device, contrary" ] # [ doc = " to the assumption made by this function." ] # [ doc = "" ] # [ doc = " If a context has been created via the driver API and is current to the" ] # [ doc = " calling thread, the flags for that context are always returned." ] # [ doc = "" ] # [ doc = " Flags returned by this function may specifically include ::cudaDeviceMapHost" ] # [ doc = " even though it is not accepted by ::cudaSetDeviceFlags because it is" ] # [ doc = " implicit in runtime API flags.  The reason for this is that the current" ] # [ doc = " context may have been created via the driver API in which case the flag is" ] # [ doc = " not implicit and may be unset." ] # [ doc = "" ] # [ doc = " \\param flags - Pointer to store the device flags" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = "" ] # [ doc = " \\sa ::cudaGetDevice, ::cudaGetDeviceProperties," ] # [ doc = " ::cudaSetDevice, ::cudaSetDeviceFlags," ] # [ doc = " ::cuCtxGetFlags," ] # [ doc = " ::cuDevicePrimaryCtxGetState" ] pub fn cudaGetDeviceFlags ( flags : * mut :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Create an asynchronous stream" ] # [ doc = "" ] # [ doc = " Creates a new asynchronous stream." ] # [ doc = "" ] # [ doc = " \\param pStream - Pointer to new stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreateWithPriority," ] # [ doc = " ::cudaStreamCreateWithFlags," ] # [ doc = " ::cudaStreamGetPriority," ] # [ doc = " ::cudaStreamGetFlags," ] # [ doc = " ::cudaStreamQuery," ] # [ doc = " ::cudaStreamSynchronize," ] # [ doc = " ::cudaStreamWaitEvent," ] # [ doc = " ::cudaStreamAddCallback," ] # [ doc = " ::cudaStreamDestroy," ] # [ doc = " ::cuStreamCreate" ] pub fn cudaStreamCreate ( pStream : * mut cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Create an asynchronous stream" ] # [ doc = "" ] # [ doc = " Creates a new asynchronous stream.  The \\p flags argument determines the" ] # [ doc = " behaviors of the stream.  Valid values for \\p flags are" ] # [ doc = " - ::cudaStreamDefault: Default stream creation flag." ] # [ doc = " - ::cudaStreamNonBlocking: Specifies that work running in the created" ] # [ doc = "   stream may run concurrently with work in stream 0 (the NULL stream), and that" ] # [ doc = "   the created stream should perform no implicit synchronization with stream 0." ] # [ doc = "" ] # [ doc = " \\param pStream - Pointer to new stream identifier" ] # [ doc = " \\param flags   - Parameters for stream creation" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate," ] # [ doc = " ::cudaStreamCreateWithPriority," ] # [ doc = " ::cudaStreamGetFlags," ] # [ doc = " ::cudaStreamQuery," ] # [ doc = " ::cudaStreamSynchronize," ] # [ doc = " ::cudaStreamWaitEvent," ] # [ doc = " ::cudaStreamAddCallback," ] # [ doc = " ::cudaStreamDestroy," ] # [ doc = " ::cuStreamCreate" ] pub fn cudaStreamCreateWithFlags ( pStream : * mut cudaStream_t , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Create an asynchronous stream with the specified priority" ] # [ doc = "" ] # [ doc = " Creates a stream with the specified priority and returns a handle in \\p pStream." ] # [ doc = " This API alters the scheduler priority of work in the stream. Work in a higher" ] # [ doc = " priority stream may preempt work already executing in a low priority stream." ] # [ doc = "" ] # [ doc = " \\p priority follows a convention where lower numbers represent higher priorities." ] # [ doc = " \'0\' represents default priority. The range of meaningful numerical priorities can" ] # [ doc = " be queried using ::cudaDeviceGetStreamPriorityRange. If the specified priority is" ] # [ doc = " outside the numerical range returned by ::cudaDeviceGetStreamPriorityRange," ] # [ doc = " it will automatically be clamped to the lowest or the highest number in the range." ] # [ doc = "" ] # [ doc = " \\param pStream  - Pointer to new stream identifier" ] # [ doc = " \\param flags    - Flags for stream creation. See ::cudaStreamCreateWithFlags for a list of valid flags that can be passed" ] # [ doc = " \\param priority - Priority of the stream. Lower numbers represent higher priorities." ] # [ doc = "                   See ::cudaDeviceGetStreamPriorityRange for more information about" ] # [ doc = "                   the meaningful stream priorities that can be passed." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\note Stream priorities are supported only on GPUs" ] # [ doc = " with compute capability 3.5 or higher." ] # [ doc = "" ] # [ doc = " \\note In the current implementation, only compute kernels launched in" ] # [ doc = " priority streams are affected by the stream\'s priority. Stream priorities have" ] # [ doc = " no effect on host-to-device and device-to-host memory operations." ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate," ] # [ doc = " ::cudaStreamCreateWithFlags," ] # [ doc = " ::cudaDeviceGetStreamPriorityRange," ] # [ doc = " ::cudaStreamGetPriority," ] # [ doc = " ::cudaStreamQuery," ] # [ doc = " ::cudaStreamWaitEvent," ] # [ doc = " ::cudaStreamAddCallback," ] # [ doc = " ::cudaStreamSynchronize," ] # [ doc = " ::cudaStreamDestroy," ] # [ doc = " ::cuStreamCreateWithPriority" ] pub fn cudaStreamCreateWithPriority ( pStream : * mut cudaStream_t , flags : :: std :: os :: raw :: c_uint , priority : :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Destroys and cleans up an asynchronous stream" ] # [ doc = "" ] # [ doc = " Destroys and cleans up the asynchronous stream specified by \\p stream." ] # [ doc = "" ] # [ doc = " In case the device is still doing work in the stream \\p stream" ] # [ doc = " when ::cudaStreamDestroy() is called, the function will return immediately" ] # [ doc = " and the resources associated with \\p stream will be released automatically" ] # [ doc = " once the device has completed all work in \\p stream." ] # [ doc = "" ] # [ doc = " \\param stream - Stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidResourceHandle" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate," ] # [ doc = " ::cudaStreamCreateWithFlags," ] # [ doc = " ::cudaStreamQuery," ] # [ doc = " ::cudaStreamWaitEvent," ] # [ doc = " ::cudaStreamSynchronize," ] # [ doc = " ::cudaStreamAddCallback," ] # [ doc = " ::cuStreamDestroy" ] pub fn cudaStreamDestroy ( stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Make a compute stream wait on an event" ] # [ doc = "" ] # [ doc = " Makes all future work submitted to \\p stream wait for all work captured in" ] # [ doc = " \\p event.  See ::cudaEventRecord() for details on what is captured by an event." ] # [ doc = " The synchronization will be performed efficiently on the device when applicable." ] # [ doc = " \\p event may be from a different device than \\p stream." ] # [ doc = "" ] # [ doc = " \\param stream - Stream to wait" ] # [ doc = " \\param event  - Event to wait on" ] # [ doc = " \\param flags  - Parameters for the operation (must be 0)" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidResourceHandle" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate, ::cudaStreamCreateWithFlags, ::cudaStreamQuery, ::cudaStreamSynchronize, ::cudaStreamAddCallback, ::cudaStreamDestroy," ] # [ doc = " ::cuStreamWaitEvent" ] pub fn cudaStreamWaitEvent ( stream : cudaStream_t , event : cudaEvent_t , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Add a callback to a compute stream" ] # [ doc = "" ] # [ doc = " Adds a callback to be called on the host after all currently enqueued" ] # [ doc = " items in the stream have completed.  For each" ] # [ doc = " cudaStreamAddCallback call, a callback will be executed exactly once." ] # [ doc = " The callback will block later work in the stream until it is finished." ] # [ doc = "" ] # [ doc = " The callback may be passed ::cudaSuccess or an error code.  In the event" ] # [ doc = " of a device error, all subsequently executed callbacks will receive an" ] # [ doc = " appropriate ::cudaError_t." ] # [ doc = "" ] # [ doc = " Callbacks must not make any CUDA API calls.  Attempting to use CUDA APIs" ] # [ doc = " will result in ::cudaErrorNotPermitted.  Callbacks must not perform any" ] # [ doc = " synchronization that may depend on outstanding device work or other callbacks" ] # [ doc = " that are not mandated to run earlier.  Callbacks without a mandated order" ] # [ doc = " (in independent streams) execute in undefined order and may be serialized." ] # [ doc = "" ] # [ doc = " For the purposes of Unified Memory, callback execution makes a number of" ] # [ doc = " guarantees:" ] # [ doc = " <ul>" ] # [ doc = "   <li>The callback stream is considered idle for the duration of the" ] # [ doc = "   callback.  Thus, for example, a callback may always use memory attached" ] # [ doc = "   to the callback stream.</li>" ] # [ doc = "   <li>The start of execution of a callback has the same effect as" ] # [ doc = "   synchronizing an event recorded in the same stream immediately prior to" ] # [ doc = "   the callback.  It thus synchronizes streams which have been \"joined\"" ] # [ doc = "   prior to the callback.</li>" ] # [ doc = "   <li>Adding device work to any stream does not have the effect of making" ] # [ doc = "   the stream active until all preceding callbacks have executed.  Thus, for" ] # [ doc = "   example, a callback might use global attached memory even if work has" ] # [ doc = "   been added to another stream, if it has been properly ordered with an" ] # [ doc = "   event.</li>" ] # [ doc = "   <li>Completion of a callback does not cause a stream to become" ] # [ doc = "   active except as described above.  The callback stream will remain idle" ] # [ doc = "   if no device work follows the callback, and will remain idle across" ] # [ doc = "   consecutive callbacks without device work in between.  Thus, for example," ] # [ doc = "   stream synchronization can be done by signaling from a callback at the" ] # [ doc = "   end of the stream.</li>" ] # [ doc = " </ul>" ] # [ doc = "" ] # [ doc = " \\param stream   - Stream to add callback to" ] # [ doc = " \\param callback - The function to call once preceding stream operations are complete" ] # [ doc = " \\param userData - User specified data to be passed to the callback function" ] # [ doc = " \\param flags    - Reserved for future use, must be 0" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorNotSupported" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate, ::cudaStreamCreateWithFlags, ::cudaStreamQuery, ::cudaStreamSynchronize, ::cudaStreamWaitEvent, ::cudaStreamDestroy, ::cudaMallocManaged, ::cudaStreamAttachMemAsync," ] # [ doc = " ::cuStreamAddCallback" ] pub fn cudaStreamAddCallback ( stream : cudaStream_t , callback : cudaStreamCallback_t , userData : * mut :: std :: os :: raw :: c_void , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Waits for stream tasks to complete" ] # [ doc = "" ] # [ doc = " Blocks until \\p stream has completed all operations. If the" ] # [ doc = " ::cudaDeviceScheduleBlockingSync flag was set for this device," ] # [ doc = " the host thread will block until the stream is finished with" ] # [ doc = " all of its tasks." ] # [ doc = "" ] # [ doc = " \\param stream - Stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidResourceHandle" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate, ::cudaStreamCreateWithFlags, ::cudaStreamQuery, ::cudaStreamWaitEvent, ::cudaStreamAddCallback, ::cudaStreamDestroy," ] # [ doc = " ::cuStreamSynchronize" ] pub fn cudaStreamSynchronize ( stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Queries an asynchronous stream for completion status" ] # [ doc = "" ] # [ doc = " Returns ::cudaSuccess if all operations in \\p stream have" ] # [ doc = " completed, or ::cudaErrorNotReady if not." ] # [ doc = "" ] # [ doc = " For the purposes of Unified Memory, a return value of ::cudaSuccess" ] # [ doc = " is equivalent to having called ::cudaStreamSynchronize()." ] # [ doc = "" ] # [ doc = " \\param stream - Stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorNotReady," ] # [ doc = " ::cudaErrorInvalidResourceHandle" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate, ::cudaStreamCreateWithFlags, ::cudaStreamWaitEvent, ::cudaStreamSynchronize, ::cudaStreamAddCallback, ::cudaStreamDestroy," ] # [ doc = " ::cuStreamQuery" ] pub fn cudaStreamQuery ( stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Attach memory to a stream asynchronously" ] # [ doc = "" ] # [ doc = " Enqueues an operation in \\p stream to specify stream association of" ] # [ doc = " \\p length bytes of memory starting from \\p devPtr. This function is a" ] # [ doc = " stream-ordered operation, meaning that it is dependent on, and will" ] # [ doc = " only take effect when, previous work in stream has completed. Any" ] # [ doc = " previous association is automatically replaced." ] # [ doc = "" ] # [ doc = " \\p devPtr must point to an one of the following types of memories:" ] # [ doc = " - managed memory declared using the __managed__ keyword or allocated with" ] # [ doc = "   ::cudaMallocManaged." ] # [ doc = " - a valid host-accessible region of system-allocated pageable memory. This" ] # [ doc = "   type of memory may only be specified if the device associated with the" ] # [ doc = "   stream reports a non-zero value for the device attribute" ] # [ doc = "   ::cudaDevAttrPageableMemoryAccess." ] # [ doc = "" ] # [ doc = " For managed allocations, \\p length must be either zero or the entire" ] # [ doc = " allocation\'s size. Both indicate that the entire allocation\'s stream" ] # [ doc = " association is being changed. Currently, it is not possible to change stream" ] # [ doc = " association for a portion of a managed allocation." ] # [ doc = "" ] # [ doc = " For pageable allocations, \\p length must be non-zero." ] # [ doc = "" ] # [ doc = " The stream association is specified using \\p flags which must be" ] # [ doc = " one of ::cudaMemAttachGlobal, ::cudaMemAttachHost or ::cudaMemAttachSingle." ] # [ doc = " The default value for \\p flags is ::cudaMemAttachSingle" ] # [ doc = " If the ::cudaMemAttachGlobal flag is specified, the memory can be accessed" ] # [ doc = " by any stream on any device." ] # [ doc = " If the ::cudaMemAttachHost flag is specified, the program makes a guarantee" ] # [ doc = " that it won\'t access the memory on the device from any stream on a device that" ] # [ doc = " has a zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess." ] # [ doc = " If the ::cudaMemAttachSingle flag is specified and \\p stream is associated with" ] # [ doc = " a device that has a zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess," ] # [ doc = " the program makes a guarantee that it will only access the memory on the device" ] # [ doc = " from \\p stream. It is illegal to attach singly to the NULL stream, because the" ] # [ doc = " NULL stream is a virtual global stream and not a specific stream. An error will" ] # [ doc = " be returned in this case." ] # [ doc = "" ] # [ doc = " When memory is associated with a single stream, the Unified Memory system will" ] # [ doc = " allow CPU access to this memory region so long as all operations in \\p stream" ] # [ doc = " have completed, regardless of whether other streams are active. In effect," ] # [ doc = " this constrains exclusive ownership of the managed memory region by" ] # [ doc = " an active GPU to per-stream activity instead of whole-GPU activity." ] # [ doc = "" ] # [ doc = " Accessing memory on the device from streams that are not associated with" ] # [ doc = " it will produce undefined results. No error checking is performed by the" ] # [ doc = " Unified Memory system to ensure that kernels launched into other streams" ] # [ doc = " do not access this region." ] # [ doc = "" ] # [ doc = " It is a program\'s responsibility to order calls to ::cudaStreamAttachMemAsync" ] # [ doc = " via events, synchronization or other means to ensure legal access to memory" ] # [ doc = " at all times. Data visibility and coherency will be changed appropriately" ] # [ doc = " for all kernels which follow a stream-association change." ] # [ doc = "" ] # [ doc = " If \\p stream is destroyed while data is associated with it, the association is" ] # [ doc = " removed and the association reverts to the default visibility of the allocation" ] # [ doc = " as specified at ::cudaMallocManaged. For __managed__ variables, the default" ] # [ doc = " association is always ::cudaMemAttachGlobal. Note that destroying a stream is an" ] # [ doc = " asynchronous operation, and as a result, the change to default association won\'t" ] # [ doc = " happen until all work in the stream has completed." ] # [ doc = "" ] # [ doc = " \\param stream  - Stream in which to enqueue the attach operation" ] # [ doc = " \\param devPtr  - Pointer to memory (must be a pointer to managed memory or" ] # [ doc = "                  to a valid host-accessible region of system-allocated" ] # [ doc = "                  memory)" ] # [ doc = " \\param length  - Length of memory (defaults to zero)" ] # [ doc = " \\param flags   - Must be one of ::cudaMemAttachGlobal, ::cudaMemAttachHost or ::cudaMemAttachSingle (defaults to ::cudaMemAttachSingle)" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorNotReady," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidResourceHandle" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaStreamCreate, ::cudaStreamCreateWithFlags, ::cudaStreamWaitEvent, ::cudaStreamSynchronize, ::cudaStreamAddCallback, ::cudaStreamDestroy, ::cudaMallocManaged," ] # [ doc = " ::cuStreamAttachMemAsync" ] pub fn cudaStreamAttachMemAsync ( stream : cudaStream_t , devPtr : * mut :: std :: os :: raw :: c_void , length : usize , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Creates an event object" ] # [ doc = "" ] # [ doc = " Creates an event object for the current device using ::cudaEventDefault." ] # [ doc = "" ] # [ doc = " \\param event - Newly created event" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInitializationError," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorLaunchFailure," ] # [ doc = " ::cudaErrorMemoryAllocation" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa \\ref ::cudaEventCreate(cudaEvent_t*, unsigned int) \"cudaEventCreate (C++ API)\"," ] # [ doc = " ::cudaEventCreateWithFlags, ::cudaEventRecord, ::cudaEventQuery," ] # [ doc = " ::cudaEventSynchronize, ::cudaEventDestroy, ::cudaEventElapsedTime," ] # [ doc = " ::cudaStreamWaitEvent," ] # [ doc = " ::cuEventCreate" ] pub fn cudaEventCreate ( event : * mut cudaEvent_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Creates an event object with the specified flags" ] # [ doc = "" ] # [ doc = " Creates an event object for the current device with the specified flags. Valid" ] # [ doc = " flags include:" ] # [ doc = " - ::cudaEventDefault: Default event creation flag." ] # [ doc = " - ::cudaEventBlockingSync: Specifies that event should use blocking" ] # [ doc = "   synchronization. A host thread that uses ::cudaEventSynchronize() to wait" ] # [ doc = "   on an event created with this flag will block until the event actually" ] # [ doc = "   completes." ] # [ doc = " - ::cudaEventDisableTiming: Specifies that the created event does not need" ] # [ doc = "   to record timing data.  Events created with this flag specified and" ] # [ doc = "   the ::cudaEventBlockingSync flag not specified will provide the best" ] # [ doc = "   performance when used with ::cudaStreamWaitEvent() and ::cudaEventQuery()." ] # [ doc = " - ::cudaEventInterprocess: Specifies that the created event may be used as an" ] # [ doc = "   interprocess event by ::cudaIpcGetEventHandle(). ::cudaEventInterprocess must" ] # [ doc = "   be specified along with ::cudaEventDisableTiming." ] # [ doc = "" ] # [ doc = " \\param event - Newly created event" ] # [ doc = " \\param flags - Flags for new event" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInitializationError," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorLaunchFailure," ] # [ doc = " ::cudaErrorMemoryAllocation" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa \\ref ::cudaEventCreate(cudaEvent_t*) \"cudaEventCreate (C API)\"," ] # [ doc = " ::cudaEventSynchronize, ::cudaEventDestroy, ::cudaEventElapsedTime," ] # [ doc = " ::cudaStreamWaitEvent," ] # [ doc = " ::cuEventCreate" ] pub fn cudaEventCreateWithFlags ( event : * mut cudaEvent_t , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Records an event" ] # [ doc = "" ] # [ doc = " Captures in \\p event the contents of \\p stream at the time of this call." ] # [ doc = " \\p event and \\p stream must be on the same device." ] # [ doc = " Calls such as ::cudaEventQuery() or ::cudaStreamWaitEvent() will then" ] # [ doc = " examine or wait for completion of the work that was captured. Uses of" ] # [ doc = " \\p stream after this call do not modify \\p event. See note on default" ] # [ doc = " stream behavior for what is captured in the default case." ] # [ doc = "" ] # [ doc = " ::cudaEventRecord() can be called multiple times on the same event and" ] # [ doc = " will overwrite the previously captured state. Other APIs such as" ] # [ doc = " ::cudaStreamWaitEvent() use the most recently captured state at the time" ] # [ doc = " of the API call, and are not affected by later calls to" ] # [ doc = " ::cudaEventRecord(). Before the first call to ::cudaEventRecord(), an" ] # [ doc = " event represents an empty set of work, so for example ::cudaEventQuery()" ] # [ doc = " would return ::cudaSuccess." ] # [ doc = "" ] # [ doc = " \\param event  - Event to record" ] # [ doc = " \\param stream - Stream in which to record event" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInitializationError," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorLaunchFailure" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa \\ref ::cudaEventCreate(cudaEvent_t*) \"cudaEventCreate (C API)\"," ] # [ doc = " ::cudaEventCreateWithFlags, ::cudaEventQuery," ] # [ doc = " ::cudaEventSynchronize, ::cudaEventDestroy, ::cudaEventElapsedTime," ] # [ doc = " ::cudaStreamWaitEvent," ] # [ doc = " ::cuEventRecord" ] pub fn cudaEventRecord ( event : cudaEvent_t , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Queries an event\'s status" ] # [ doc = "" ] # [ doc = " Queries the status of all work currently captured by \\p event. See" ] # [ doc = " ::cudaEventRecord() for details on what is captured by an event." ] # [ doc = "" ] # [ doc = " Returns ::cudaSuccess if all captured work has been completed, or" ] # [ doc = " ::cudaErrorNotReady if any captured work is incomplete." ] # [ doc = "" ] # [ doc = " For the purposes of Unified Memory, a return value of ::cudaSuccess" ] # [ doc = " is equivalent to having called ::cudaEventSynchronize()." ] # [ doc = "" ] # [ doc = " \\param event - Event to query" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorNotReady," ] # [ doc = " ::cudaErrorInitializationError," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorLaunchFailure" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa \\ref ::cudaEventCreate(cudaEvent_t*) \"cudaEventCreate (C API)\"," ] # [ doc = " ::cudaEventCreateWithFlags, ::cudaEventRecord," ] # [ doc = " ::cudaEventSynchronize, ::cudaEventDestroy, ::cudaEventElapsedTime," ] # [ doc = " ::cuEventQuery" ] pub fn cudaEventQuery ( event : cudaEvent_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Waits for an event to complete" ] # [ doc = "" ] # [ doc = " Waits until the completion of all work currently captured in \\p event." ] # [ doc = " See ::cudaEventRecord() for details on what is captured by an event." ] # [ doc = "" ] # [ doc = " Waiting for an event that was created with the ::cudaEventBlockingSync" ] # [ doc = " flag will cause the calling CPU thread to block until the event has" ] # [ doc = " been completed by the device.  If the ::cudaEventBlockingSync flag has" ] # [ doc = " not been set, then the CPU thread will busy-wait until the event has" ] # [ doc = " been completed by the device." ] # [ doc = "" ] # [ doc = " \\param event - Event to wait for" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInitializationError," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorLaunchFailure" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa \\ref ::cudaEventCreate(cudaEvent_t*) \"cudaEventCreate (C API)\"," ] # [ doc = " ::cudaEventCreateWithFlags, ::cudaEventRecord," ] # [ doc = " ::cudaEventQuery, ::cudaEventDestroy, ::cudaEventElapsedTime," ] # [ doc = " ::cuEventSynchronize" ] pub fn cudaEventSynchronize ( event : cudaEvent_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Destroys an event object" ] # [ doc = "" ] # [ doc = " Destroys the event specified by \\p event." ] # [ doc = "" ] # [ doc = " An event may be destroyed before it is complete (i.e., while" ] # [ doc = " ::cudaEventQuery() would return ::cudaErrorNotReady). In this case, the" ] # [ doc = " call does not block on completion of the event, and any associated" ] # [ doc = " resources will automatically be released asynchronously at completion." ] # [ doc = "" ] # [ doc = " \\param event - Event to destroy" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInitializationError," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorLaunchFailure" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa \\ref ::cudaEventCreate(cudaEvent_t*) \"cudaEventCreate (C API)\"," ] # [ doc = " ::cudaEventCreateWithFlags, ::cudaEventQuery," ] # [ doc = " ::cudaEventSynchronize, ::cudaEventRecord, ::cudaEventElapsedTime," ] # [ doc = " ::cuEventDestroy" ] pub fn cudaEventDestroy ( event : cudaEvent_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Computes the elapsed time between events" ] # [ doc = "" ] # [ doc = " Computes the elapsed time between two events (in milliseconds with a" ] # [ doc = " resolution of around 0.5 microseconds)." ] # [ doc = "" ] # [ doc = " If either event was last recorded in a non-NULL stream, the resulting time" ] # [ doc = " may be greater than expected (even if both used the same stream handle). This" ] # [ doc = " happens because the ::cudaEventRecord() operation takes place asynchronously" ] # [ doc = " and there is no guarantee that the measured latency is actually just between" ] # [ doc = " the two events. Any number of other different stream operations could execute" ] # [ doc = " in between the two measured events, thus altering the timing in a significant" ] # [ doc = " way." ] # [ doc = "" ] # [ doc = " If ::cudaEventRecord() has not been called on either event, then" ] # [ doc = " ::cudaErrorInvalidResourceHandle is returned. If ::cudaEventRecord() has been" ] # [ doc = " called on both events but one or both of them has not yet been completed" ] # [ doc = " (that is, ::cudaEventQuery() would return ::cudaErrorNotReady on at least one" ] # [ doc = " of the events), ::cudaErrorNotReady is returned. If either event was created" ] # [ doc = " with the ::cudaEventDisableTiming flag, then this function will return" ] # [ doc = " ::cudaErrorInvalidResourceHandle." ] # [ doc = "" ] # [ doc = " \\param ms    - Time between \\p start and \\p end in ms" ] # [ doc = " \\param start - Starting event" ] # [ doc = " \\param end   - Ending event" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorNotReady," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInitializationError," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorLaunchFailure" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa \\ref ::cudaEventCreate(cudaEvent_t*) \"cudaEventCreate (C API)\"," ] # [ doc = " ::cudaEventCreateWithFlags, ::cudaEventQuery," ] # [ doc = " ::cudaEventSynchronize, ::cudaEventDestroy, ::cudaEventRecord," ] # [ doc = " ::cuEventElapsedTime" ] pub fn cudaEventElapsedTime ( ms : * mut f32 , start : cudaEvent_t , end : cudaEvent_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Allocates memory that will be automatically managed by the Unified Memory system" ] # [ doc = "" ] # [ doc = " Allocates \\p size bytes of managed memory on the device and returns in" ] # [ doc = " \\p *devPtr a pointer to the allocated memory. If the device doesn\'t support" ] # [ doc = " allocating managed memory, ::cudaErrorNotSupported is returned. Support" ] # [ doc = " for managed memory can be queried using the device attribute" ] # [ doc = " ::cudaDevAttrManagedMemory. The allocated memory is suitably" ] # [ doc = " aligned for any kind of variable. The memory is not cleared. If \\p size" ] # [ doc = " is 0, ::cudaMallocManaged returns ::cudaErrorInvalidValue. The pointer" ] # [ doc = " is valid on the CPU and on all GPUs in the system that support managed memory." ] # [ doc = " All accesses to this pointer must obey the Unified Memory programming model." ] # [ doc = "" ] # [ doc = " \\p flags specifies the default stream association for this allocation." ] # [ doc = " \\p flags must be one of ::cudaMemAttachGlobal or ::cudaMemAttachHost. The" ] # [ doc = " default value for \\p flags is ::cudaMemAttachGlobal." ] # [ doc = " If ::cudaMemAttachGlobal is specified, then this memory is accessible from" ] # [ doc = " any stream on any device. If ::cudaMemAttachHost is specified, then the" ] # [ doc = " allocation should not be accessed from devices that have a zero value for the" ] # [ doc = " device attribute ::cudaDevAttrConcurrentManagedAccess; an explicit call to" ] # [ doc = " ::cudaStreamAttachMemAsync will be required to enable access on such devices." ] # [ doc = "" ] # [ doc = " If the association is later changed via ::cudaStreamAttachMemAsync to" ] # [ doc = " a single stream, the default association, as specifed during ::cudaMallocManaged," ] # [ doc = " is restored when that stream is destroyed. For __managed__ variables, the" ] # [ doc = " default association is always ::cudaMemAttachGlobal. Note that destroying a" ] # [ doc = " stream is an asynchronous operation, and as a result, the change to default" ] # [ doc = " association won\'t happen until all work in the stream has completed." ] # [ doc = "" ] # [ doc = " Memory allocated with ::cudaMallocManaged should be released with ::cudaFree." ] # [ doc = "" ] # [ doc = " Device memory oversubscription is possible for GPUs that have a non-zero value for the" ] # [ doc = " device attribute ::cudaDevAttrConcurrentManagedAccess. Managed memory on" ] # [ doc = " such GPUs may be evicted from device memory to host memory at any time by the Unified" ] # [ doc = " Memory driver in order to make room for other allocations." ] # [ doc = "" ] # [ doc = " In a multi-GPU system where all GPUs have a non-zero value for the device attribute" ] # [ doc = " ::cudaDevAttrConcurrentManagedAccess, managed memory may not be populated when this" ] # [ doc = " API returns and instead may be populated on access. In such systems, managed memory can" ] # [ doc = " migrate to any processor\'s memory at any time. The Unified Memory driver will employ heuristics to" ] # [ doc = " maintain data locality and prevent excessive page faults to the extent possible. The application" ] # [ doc = " can also guide the driver about memory usage patterns via ::cudaMemAdvise. The application" ] # [ doc = " can also explicitly migrate memory to a desired processor\'s memory via" ] # [ doc = " ::cudaMemPrefetchAsync." ] # [ doc = "" ] # [ doc = " In a multi-GPU system where all of the GPUs have a zero value for the device attribute" ] # [ doc = " ::cudaDevAttrConcurrentManagedAccess and all the GPUs have peer-to-peer support" ] # [ doc = " with each other, the physical storage for managed memory is created on the GPU which is active" ] # [ doc = " at the time ::cudaMallocManaged is called. All other GPUs will reference the data at reduced" ] # [ doc = " bandwidth via peer mappings over the PCIe bus. The Unified Memory driver does not migrate" ] # [ doc = " memory among such GPUs." ] # [ doc = "" ] # [ doc = " In a multi-GPU system where not all GPUs have peer-to-peer support with each other and" ] # [ doc = " where the value of the device attribute ::cudaDevAttrConcurrentManagedAccess" ] # [ doc = " is zero for at least one of those GPUs, the location chosen for physical storage of managed" ] # [ doc = " memory is system-dependent." ] # [ doc = " - On Linux, the location chosen will be device memory as long as the current set of active" ] # [ doc = " contexts are on devices that either have peer-to-peer support with each other or have a" ] # [ doc = " non-zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess." ] # [ doc = " If there is an active context on a GPU that does not have a non-zero value for that device" ] # [ doc = " attribute and it does not have peer-to-peer support with the other devices that have active" ] # [ doc = " contexts on them, then the location for physical storage will be \'zero-copy\' or host memory." ] # [ doc = " Note that this means that managed memory that is located in device memory is migrated to" ] # [ doc = " host memory if a new context is created on a GPU that doesn\'t have a non-zero value for" ] # [ doc = " the device attribute and does not support peer-to-peer with at least one of the other devices" ] # [ doc = " that has an active context. This in turn implies that context creation may fail if there is" ] # [ doc = " insufficient host memory to migrate all managed allocations." ] # [ doc = " - On Windows, the physical storage is always created in \'zero-copy\' or host memory." ] # [ doc = " All GPUs will reference the data at reduced bandwidth over the PCIe bus. In these" ] # [ doc = " circumstances, use of the environment variable CUDA_VISIBLE_DEVICES is recommended to" ] # [ doc = " restrict CUDA to only use those GPUs that have peer-to-peer support." ] # [ doc = " Alternatively, users can also set CUDA_MANAGED_FORCE_DEVICE_ALLOC to a non-zero" ] # [ doc = " value to force the driver to always use device memory for physical storage." ] # [ doc = " When this environment variable is set to a non-zero value, all devices used in" ] # [ doc = " that process that support managed memory have to be peer-to-peer compatible" ] # [ doc = " with each other. The error ::cudaErrorInvalidDevice will be returned if a device" ] # [ doc = " that supports managed memory is used and it is not peer-to-peer compatible with" ] # [ doc = " any of the other managed memory supporting devices that were previously used in" ] # [ doc = " that process, even if ::cudaDeviceReset has been called on those devices. These" ] # [ doc = " environment variables are described in the CUDA programming guide under the" ] # [ doc = " \"CUDA environment variables\" section." ] # [ doc = "" ] # [ doc = " \\param devPtr - Pointer to allocated device memory" ] # [ doc = " \\param size   - Requested allocation size in bytes" ] # [ doc = " \\param flags  - Must be either ::cudaMemAttachGlobal or ::cudaMemAttachHost (defaults to ::cudaMemAttachGlobal)" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorMemoryAllocation," ] # [ doc = " ::cudaErrorNotSupported," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMallocPitch, ::cudaFree, ::cudaMallocArray, ::cudaFreeArray," ] # [ doc = " ::cudaMalloc3D, ::cudaMalloc3DArray," ] # [ doc = " \\ref ::cudaMallocHost(void**, size_t) \"cudaMallocHost (C API)\"," ] # [ doc = " ::cudaFreeHost, ::cudaHostAlloc, ::cudaDeviceGetAttribute, ::cudaStreamAttachMemAsync," ] # [ doc = " ::cuMemAllocManaged" ] pub fn cudaMallocManaged ( devPtr : * mut * mut :: std :: os :: raw :: c_void , size : usize , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Allocate memory on the device" ] # [ doc = "" ] # [ doc = " Allocates \\p size bytes of linear memory on the device and returns in" ] # [ doc = " \\p *devPtr a pointer to the allocated memory. The allocated memory is" ] # [ doc = " suitably aligned for any kind of variable. The memory is not cleared." ] # [ doc = " ::cudaMalloc() returns ::cudaErrorMemoryAllocation in case of failure." ] # [ doc = "" ] # [ doc = " The device version of ::cudaFree cannot be used with a \\p *devPtr" ] # [ doc = " allocated using the host API, and vice versa." ] # [ doc = "" ] # [ doc = " \\param devPtr - Pointer to allocated device memory" ] # [ doc = " \\param size   - Requested allocation size in bytes" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorMemoryAllocation" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMallocPitch, ::cudaFree, ::cudaMallocArray, ::cudaFreeArray," ] # [ doc = " ::cudaMalloc3D, ::cudaMalloc3DArray," ] # [ doc = " \\ref ::cudaMallocHost(void**, size_t) \"cudaMallocHost (C API)\"," ] # [ doc = " ::cudaFreeHost, ::cudaHostAlloc," ] # [ doc = " ::cuMemAlloc" ] pub fn cudaMalloc ( devPtr : * mut * mut :: std :: os :: raw :: c_void , size : usize ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Allocates page-locked memory on the host" ] # [ doc = "" ] # [ doc = " Allocates \\p size bytes of host memory that is page-locked and accessible" ] # [ doc = " to the device. The driver tracks the virtual memory ranges allocated with" ] # [ doc = " this function and automatically accelerates calls to functions such as" ] # [ doc = " ::cudaMemcpy*(). Since the memory can be accessed directly by the device," ] # [ doc = " it can be read or written with much higher bandwidth than pageable memory" ] # [ doc = " obtained with functions such as ::malloc(). Allocating excessive amounts of" ] # [ doc = " memory with ::cudaMallocHost() may degrade system performance, since it" ] # [ doc = " reduces the amount of memory available to the system for paging. As a" ] # [ doc = " result, this function is best used sparingly to allocate staging areas for" ] # [ doc = " data exchange between host and device." ] # [ doc = "" ] # [ doc = " \\param ptr  - Pointer to allocated host memory" ] # [ doc = " \\param size - Requested allocation size in bytes" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorMemoryAllocation" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMalloc, ::cudaMallocPitch, ::cudaMallocArray, ::cudaMalloc3D," ] # [ doc = " ::cudaMalloc3DArray, ::cudaHostAlloc, ::cudaFree, ::cudaFreeArray," ] # [ doc = " \\ref ::cudaMallocHost(void**, size_t, unsigned int) \"cudaMallocHost (C++ API)\"," ] # [ doc = " ::cudaFreeHost, ::cudaHostAlloc," ] # [ doc = " ::cuMemAllocHost" ] pub fn cudaMallocHost ( ptr : * mut * mut :: std :: os :: raw :: c_void , size : usize ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Frees memory on the device" ] # [ doc = "" ] # [ doc = " Frees the memory space pointed to by \\p devPtr, which must have been" ] # [ doc = " returned by a previous call to ::cudaMalloc() or ::cudaMallocPitch()." ] # [ doc = " Otherwise, or if ::cudaFree(\\p devPtr) has already been called before," ] # [ doc = " an error is returned. If \\p devPtr is 0, no operation is performed." ] # [ doc = " ::cudaFree() returns ::cudaErrorInvalidDevicePointer in case of failure." ] # [ doc = "" ] # [ doc = " The device version of ::cudaFree cannot be used with a \\p *devPtr" ] # [ doc = " allocated using the host API, and vice versa." ] # [ doc = "" ] # [ doc = " \\param devPtr - Device pointer to memory to free" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidDevicePointer," ] # [ doc = " ::cudaErrorInitializationError" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMalloc, ::cudaMallocPitch, ::cudaMallocArray, ::cudaFreeArray," ] # [ doc = " \\ref ::cudaMallocHost(void**, size_t) \"cudaMallocHost (C API)\"," ] # [ doc = " ::cudaFreeHost, ::cudaMalloc3D, ::cudaMalloc3DArray," ] # [ doc = " ::cudaHostAlloc," ] # [ doc = " ::cuMemFree" ] pub fn cudaFree ( devPtr : * mut :: std :: os :: raw :: c_void ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Frees page-locked memory" ] # [ doc = "" ] # [ doc = " Frees the memory space pointed to by \\p hostPtr, which must have been" ] # [ doc = " returned by a previous call to ::cudaMallocHost() or ::cudaHostAlloc()." ] # [ doc = "" ] # [ doc = " \\param ptr - Pointer to memory to free" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInitializationError" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMalloc, ::cudaMallocPitch, ::cudaFree, ::cudaMallocArray," ] # [ doc = " ::cudaFreeArray," ] # [ doc = " \\ref ::cudaMallocHost(void**, size_t) \"cudaMallocHost (C API)\"," ] # [ doc = " ::cudaMalloc3D, ::cudaMalloc3DArray, ::cudaHostAlloc," ] # [ doc = " ::cuMemFreeHost" ] pub fn cudaFreeHost ( ptr : * mut :: std :: os :: raw :: c_void ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Allocates page-locked memory on the host" ] # [ doc = "" ] # [ doc = " Allocates \\p size bytes of host memory that is page-locked and accessible" ] # [ doc = " to the device. The driver tracks the virtual memory ranges allocated with" ] # [ doc = " this function and automatically accelerates calls to functions such as" ] # [ doc = " ::cudaMemcpy(). Since the memory can be accessed directly by the device, it" ] # [ doc = " can be read or written with much higher bandwidth than pageable memory" ] # [ doc = " obtained with functions such as ::malloc(). Allocating excessive amounts of" ] # [ doc = " pinned memory may degrade system performance, since it reduces the amount" ] # [ doc = " of memory available to the system for paging. As a result, this function is" ] # [ doc = " best used sparingly to allocate staging areas for data exchange between host" ] # [ doc = " and device." ] # [ doc = "" ] # [ doc = " The \\p flags parameter enables different options to be specified that affect" ] # [ doc = " the allocation, as follows." ] # [ doc = " - ::cudaHostAllocDefault: This flag\'s value is defined to be 0 and causes" ] # [ doc = " ::cudaHostAlloc() to emulate ::cudaMallocHost()." ] # [ doc = " - ::cudaHostAllocPortable: The memory returned by this call will be" ] # [ doc = " considered as pinned memory by all CUDA contexts, not just the one that" ] # [ doc = " performed the allocation." ] # [ doc = " - ::cudaHostAllocMapped: Maps the allocation into the CUDA address space." ] # [ doc = " The device pointer to the memory may be obtained by calling" ] # [ doc = " ::cudaHostGetDevicePointer()." ] # [ doc = " - ::cudaHostAllocWriteCombined: Allocates the memory as write-combined (WC)." ] # [ doc = " WC memory can be transferred across the PCI Express bus more quickly on some" ] # [ doc = " system configurations, but cannot be read efficiently by most CPUs.  WC" ] # [ doc = " memory is a good option for buffers that will be written by the CPU and read" ] # [ doc = " by the device via mapped pinned memory or host->device transfers." ] # [ doc = "" ] # [ doc = " All of these flags are orthogonal to one another: a developer may allocate" ] # [ doc = " memory that is portable, mapped and/or write-combined with no restrictions." ] # [ doc = "" ] # [ doc = " In order for the ::cudaHostAllocMapped flag to have any effect, the CUDA context" ] # [ doc = " must support the ::cudaDeviceMapHost flag, which can be checked via" ] # [ doc = " ::cudaGetDeviceFlags(). The ::cudaDeviceMapHost flag is implicitly set for" ] # [ doc = " contexts created via the runtime API." ] # [ doc = "" ] # [ doc = " The ::cudaHostAllocMapped flag may be specified on CUDA contexts for devices" ] # [ doc = " that do not support mapped pinned memory. The failure is deferred to" ] # [ doc = " ::cudaHostGetDevicePointer() because the memory may be mapped into other" ] # [ doc = " CUDA contexts via the ::cudaHostAllocPortable flag." ] # [ doc = "" ] # [ doc = " Memory allocated by this function must be freed with ::cudaFreeHost()." ] # [ doc = "" ] # [ doc = " \\param pHost - Device pointer to allocated memory" ] # [ doc = " \\param size  - Requested allocation size in bytes" ] # [ doc = " \\param flags - Requested properties of allocated memory" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorMemoryAllocation" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaSetDeviceFlags," ] # [ doc = " \\ref ::cudaMallocHost(void**, size_t) \"cudaMallocHost (C API)\"," ] # [ doc = " ::cudaFreeHost," ] # [ doc = " ::cudaGetDeviceFlags," ] # [ doc = " ::cuMemHostAlloc" ] pub fn cudaHostAlloc ( pHost : * mut * mut :: std :: os :: raw :: c_void , size : usize , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Registers an existing host memory range for use by CUDA" ] # [ doc = "" ] # [ doc = " Page-locks the memory range specified by \\p ptr and \\p size and maps it" ] # [ doc = " for the device(s) as specified by \\p flags. This memory range also is added" ] # [ doc = " to the same tracking mechanism as ::cudaHostAlloc() to automatically accelerate" ] # [ doc = " calls to functions such as ::cudaMemcpy(). Since the memory can be accessed" ] # [ doc = " directly by the device, it can be read or written with much higher bandwidth" ] # [ doc = " than pageable memory that has not been registered.  Page-locking excessive" ] # [ doc = " amounts of memory may degrade system performance, since it reduces the amount" ] # [ doc = " of memory available to the system for paging. As a result, this function is" ] # [ doc = " best used sparingly to register staging areas for data exchange between" ] # [ doc = " host and device." ] # [ doc = "" ] # [ doc = " ::cudaHostRegister is supported only on I/O coherent devices that have a non-zero" ] # [ doc = " value for the device attribute ::cudaDevAttrHostRegisterSupported." ] # [ doc = "" ] # [ doc = " The \\p flags parameter enables different options to be specified that" ] # [ doc = " affect the allocation, as follows." ] # [ doc = "" ] # [ doc = " - ::cudaHostRegisterDefault: On a system with unified virtual addressing," ] # [ doc = "   the memory will be both mapped and portable.  On a system with no unified" ] # [ doc = "   virtual addressing, the memory will be neither mapped nor portable." ] # [ doc = "" ] # [ doc = " - ::cudaHostRegisterPortable: The memory returned by this call will be" ] # [ doc = "   considered as pinned memory by all CUDA contexts, not just the one that" ] # [ doc = "   performed the allocation." ] # [ doc = "" ] # [ doc = " - ::cudaHostRegisterMapped: Maps the allocation into the CUDA address" ] # [ doc = "   space. The device pointer to the memory may be obtained by calling" ] # [ doc = "   ::cudaHostGetDevicePointer()." ] # [ doc = "" ] # [ doc = " - ::cudaHostRegisterIoMemory: The passed memory pointer is treated as" ] # [ doc = "   pointing to some memory-mapped I/O space, e.g. belonging to a" ] # [ doc = "   third-party PCIe device, and it will marked as non cache-coherent and" ] # [ doc = "   contiguous." ] # [ doc = "" ] # [ doc = " All of these flags are orthogonal to one another: a developer may page-lock" ] # [ doc = " memory that is portable or mapped with no restrictions." ] # [ doc = "" ] # [ doc = " The CUDA context must have been created with the ::cudaMapHost flag in" ] # [ doc = " order for the ::cudaHostRegisterMapped flag to have any effect." ] # [ doc = "" ] # [ doc = " The ::cudaHostRegisterMapped flag may be specified on CUDA contexts for" ] # [ doc = " devices that do not support mapped pinned memory. The failure is deferred" ] # [ doc = " to ::cudaHostGetDevicePointer() because the memory may be mapped into" ] # [ doc = " other CUDA contexts via the ::cudaHostRegisterPortable flag." ] # [ doc = "" ] # [ doc = " For devices that have a non-zero value for the device attribute" ] # [ doc = " ::cudaDevAttrCanUseHostPointerForRegisteredMem, the memory" ] # [ doc = " can also be accessed from the device using the host pointer \\p ptr." ] # [ doc = " The device pointer returned by ::cudaHostGetDevicePointer() may or may not" ] # [ doc = " match the original host pointer \\p ptr and depends on the devices visible to the" ] # [ doc = " application. If all devices visible to the application have a non-zero value for the" ] # [ doc = " device attribute, the device pointer returned by ::cudaHostGetDevicePointer()" ] # [ doc = " will match the original pointer \\p ptr. If any device visible to the application" ] # [ doc = " has a zero value for the device attribute, the device pointer returned by" ] # [ doc = " ::cudaHostGetDevicePointer() will not match the original host pointer \\p ptr," ] # [ doc = " but it will be suitable for use on all devices provided Unified Virtual Addressing" ] # [ doc = " is enabled. In such systems, it is valid to access the memory using either pointer" ] # [ doc = " on devices that have a non-zero value for the device attribute. Note however that" ] # [ doc = " such devices should access the memory using only of the two pointers and not both." ] # [ doc = "" ] # [ doc = " The memory page-locked by this function must be unregistered with ::cudaHostUnregister()." ] # [ doc = "" ] # [ doc = " \\param ptr   - Host pointer to memory to page-lock" ] # [ doc = " \\param size  - Size in bytes of the address range to page-lock in bytes" ] # [ doc = " \\param flags - Flags for allocation request" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorMemoryAllocation," ] # [ doc = " ::cudaErrorHostMemoryAlreadyRegistered," ] # [ doc = " ::cudaErrorNotSupported" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaHostUnregister, ::cudaHostGetFlags, ::cudaHostGetDevicePointer," ] # [ doc = " ::cuMemHostRegister" ] pub fn cudaHostRegister ( ptr : * mut :: std :: os :: raw :: c_void , size : usize , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Unregisters a memory range that was registered with cudaHostRegister" ] # [ doc = "" ] # [ doc = " Unmaps the memory range whose base address is specified by \\p ptr, and makes" ] # [ doc = " it pageable again." ] # [ doc = "" ] # [ doc = " The base address must be the same one specified to ::cudaHostRegister()." ] # [ doc = "" ] # [ doc = " \\param ptr - Host pointer to memory to unregister" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorHostMemoryNotRegistered" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaHostUnregister," ] # [ doc = " ::cuMemHostUnregister" ] pub fn cudaHostUnregister ( ptr : * mut :: std :: os :: raw :: c_void ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Passes back device pointer of mapped host memory allocated by" ] # [ doc = " cudaHostAlloc or registered by cudaHostRegister" ] # [ doc = "" ] # [ doc = " Passes back the device pointer corresponding to the mapped, pinned host" ] # [ doc = " buffer allocated by ::cudaHostAlloc() or registered by ::cudaHostRegister()." ] # [ doc = "" ] # [ doc = " ::cudaHostGetDevicePointer() will fail if the ::cudaDeviceMapHost flag was" ] # [ doc = " not specified before deferred context creation occurred, or if called on a" ] # [ doc = " device that does not support mapped, pinned memory." ] # [ doc = "" ] # [ doc = " For devices that have a non-zero value for the device attribute" ] # [ doc = " ::cudaDevAttrCanUseHostPointerForRegisteredMem, the memory" ] # [ doc = " can also be accessed from the device using the host pointer \\p pHost." ] # [ doc = " The device pointer returned by ::cudaHostGetDevicePointer() may or may not" ] # [ doc = " match the original host pointer \\p pHost and depends on the devices visible to the" ] # [ doc = " application. If all devices visible to the application have a non-zero value for the" ] # [ doc = " device attribute, the device pointer returned by ::cudaHostGetDevicePointer()" ] # [ doc = " will match the original pointer \\p pHost. If any device visible to the application" ] # [ doc = " has a zero value for the device attribute, the device pointer returned by" ] # [ doc = " ::cudaHostGetDevicePointer() will not match the original host pointer \\p pHost," ] # [ doc = " but it will be suitable for use on all devices provided Unified Virtual Addressing" ] # [ doc = " is enabled. In such systems, it is valid to access the memory using either pointer" ] # [ doc = " on devices that have a non-zero value for the device attribute. Note however that" ] # [ doc = " such devices should access the memory using only of the two pointers and not both." ] # [ doc = "" ] # [ doc = " \\p flags provides for future releases.  For now, it must be set to 0." ] # [ doc = "" ] # [ doc = " \\param pDevice - Returned device pointer for mapped memory" ] # [ doc = " \\param pHost   - Requested host pointer mapping" ] # [ doc = " \\param flags   - Flags for extensions (must be 0 for now)" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorMemoryAllocation" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaSetDeviceFlags, ::cudaHostAlloc," ] # [ doc = " ::cuMemHostGetDevicePointer" ] pub fn cudaHostGetDevicePointer ( pDevice : * mut * mut :: std :: os :: raw :: c_void , pHost : * mut :: std :: os :: raw :: c_void , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Passes back flags used to allocate pinned host memory allocated by" ] # [ doc = " cudaHostAlloc" ] # [ doc = "" ] # [ doc = " ::cudaHostGetFlags() will fail if the input pointer does not" ] # [ doc = " reside in an address range allocated by ::cudaHostAlloc()." ] # [ doc = "" ] # [ doc = " \\param pFlags - Returned flags word" ] # [ doc = " \\param pHost - Host pointer" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaHostAlloc," ] # [ doc = " ::cuMemHostGetFlags" ] pub fn cudaHostGetFlags ( pFlags : * mut :: std :: os :: raw :: c_uint , pHost : * mut :: std :: os :: raw :: c_void ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Copies data between host and device" ] # [ doc = "" ] # [ doc = " Copies \\p count bytes from the memory area pointed to by \\p src to the" ] # [ doc = " memory area pointed to by \\p dst, where \\p kind specifies the direction" ] # [ doc = " of the copy, and must be one of ::cudaMemcpyHostToHost," ] # [ doc = " ::cudaMemcpyHostToDevice, ::cudaMemcpyDeviceToHost," ] # [ doc = " ::cudaMemcpyDeviceToDevice, or ::cudaMemcpyDefault. Passing" ] # [ doc = " ::cudaMemcpyDefault is recommended, in which case the type of transfer is" ] # [ doc = " inferred from the pointer values. However, ::cudaMemcpyDefault is only" ] # [ doc = " allowed on systems that support unified virtual addressing. Calling" ] # [ doc = " ::cudaMemcpy() with dst and src pointers that do not match the direction of" ] # [ doc = " the copy results in an undefined behavior." ] # [ doc = "" ] # [ doc = " \\param dst   - Destination memory address" ] # [ doc = " \\param src   - Source memory address" ] # [ doc = " \\param count - Size in bytes to copy" ] # [ doc = " \\param kind  - Type of transfer" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidMemcpyDirection" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\note_sync" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy2D, ::cudaMemcpyToArray," ] # [ doc = " ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray," ] # [ doc = " ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray, ::cudaMemcpyToSymbol," ] # [ doc = " ::cudaMemcpyFromSymbol, ::cudaMemcpyAsync, ::cudaMemcpy2DAsync," ] # [ doc = " ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync," ] # [ doc = " ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync," ] # [ doc = " ::cudaMemcpyToSymbolAsync, ::cudaMemcpyFromSymbolAsync," ] # [ doc = " ::cuMemcpyDtoH," ] # [ doc = " ::cuMemcpyHtoD," ] # [ doc = " ::cuMemcpyDtoD," ] # [ doc = " ::cuMemcpy" ] pub fn cudaMemcpy ( dst : * mut :: std :: os :: raw :: c_void , src : * const :: std :: os :: raw :: c_void , count : usize , kind : cudaMemcpyKind ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Copies memory between two devices" ] # [ doc = "" ] # [ doc = " Copies memory from one device to memory on another device.  \\p dst is the" ] # [ doc = " base device pointer of the destination memory and \\p dstDevice is the" ] # [ doc = " destination device.  \\p src is the base device pointer of the source memory" ] # [ doc = " and \\p srcDevice is the source device.  \\p count specifies the number of bytes" ] # [ doc = " to copy." ] # [ doc = "" ] # [ doc = " Note that this function is asynchronous with respect to the host, but" ] # [ doc = " serialized with respect all pending and future asynchronous work in to the" ] # [ doc = " current device, \\p srcDevice, and \\p dstDevice (use ::cudaMemcpyPeerAsync" ] # [ doc = " to avoid this synchronization)." ] # [ doc = "" ] # [ doc = " \\param dst       - Destination device pointer" ] # [ doc = " \\param dstDevice - Destination device" ] # [ doc = " \\param src       - Source device pointer" ] # [ doc = " \\param srcDevice - Source device" ] # [ doc = " \\param count     - Size of memory copy in bytes" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_sync" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy, ::cudaMemcpyAsync, ::cudaMemcpyPeerAsync," ] # [ doc = " ::cudaMemcpy3DPeerAsync," ] # [ doc = " ::cuMemcpyPeer" ] pub fn cudaMemcpyPeer ( dst : * mut :: std :: os :: raw :: c_void , dstDevice : :: std :: os :: raw :: c_int , src : * const :: std :: os :: raw :: c_void , srcDevice : :: std :: os :: raw :: c_int , count : usize ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Copies data between host and device" ] # [ doc = "" ] # [ doc = " Copies a matrix (\\p height rows of \\p width bytes each) from the memory" ] # [ doc = " area pointed to by \\p src to the memory area pointed to by \\p dst, where" ] # [ doc = " \\p kind specifies the direction of the copy, and must be one of" ] # [ doc = " ::cudaMemcpyHostToHost, ::cudaMemcpyHostToDevice, ::cudaMemcpyDeviceToHost," ] # [ doc = " ::cudaMemcpyDeviceToDevice, or ::cudaMemcpyDefault. Passing" ] # [ doc = " ::cudaMemcpyDefault is recommended, in which case the type of transfer is" ] # [ doc = " inferred from the pointer values. However, ::cudaMemcpyDefault is only" ] # [ doc = " allowed on systems that support unified virtual addressing. \\p dpitch and" ] # [ doc = " \\p spitch are the widths in memory in bytes of the 2D arrays pointed to by" ] # [ doc = " \\p dst and \\p src, including any padding added to the end of each row. The" ] # [ doc = " memory areas may not overlap. \\p width must not exceed either \\p dpitch or" ] # [ doc = " \\p spitch. Calling ::cudaMemcpy2D() with \\p dst and \\p src pointers that do" ] # [ doc = " not match the direction of the copy results in an undefined behavior." ] # [ doc = " ::cudaMemcpy2D() returns an error if \\p dpitch or \\p spitch exceeds" ] # [ doc = " the maximum allowed." ] # [ doc = "" ] # [ doc = " \\param dst    - Destination memory address" ] # [ doc = " \\param dpitch - Pitch of destination memory" ] # [ doc = " \\param src    - Source memory address" ] # [ doc = " \\param spitch - Pitch of source memory" ] # [ doc = " \\param width  - Width of matrix transfer (columns in bytes)" ] # [ doc = " \\param height - Height of matrix transfer (rows)" ] # [ doc = " \\param kind   - Type of transfer" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidPitchValue," ] # [ doc = " ::cudaErrorInvalidMemcpyDirection" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy, ::cudaMemcpyToArray," ] # [ doc = " ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray," ] # [ doc = " ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray, ::cudaMemcpyToSymbol," ] # [ doc = " ::cudaMemcpyFromSymbol, ::cudaMemcpyAsync, ::cudaMemcpy2DAsync," ] # [ doc = " ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync," ] # [ doc = " ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync," ] # [ doc = " ::cudaMemcpyToSymbolAsync, ::cudaMemcpyFromSymbolAsync," ] # [ doc = " ::cuMemcpy2D," ] # [ doc = " ::cuMemcpy2DUnaligned" ] pub fn cudaMemcpy2D ( dst : * mut :: std :: os :: raw :: c_void , dpitch : usize , src : * const :: std :: os :: raw :: c_void , spitch : usize , width : usize , height : usize , kind : cudaMemcpyKind ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Copies data between host and device" ] # [ doc = "" ] # [ doc = " Copies \\p count bytes from the memory area pointed to by \\p src to the" ] # [ doc = " memory area pointed to by \\p dst, where \\p kind specifies the" ] # [ doc = " direction of the copy, and must be one of ::cudaMemcpyHostToHost," ] # [ doc = " ::cudaMemcpyHostToDevice, ::cudaMemcpyDeviceToHost," ] # [ doc = " ::cudaMemcpyDeviceToDevice, or ::cudaMemcpyDefault. Passing" ] # [ doc = " ::cudaMemcpyDefault is recommended, in which case the type of transfer is" ] # [ doc = " inferred from the pointer values. However, ::cudaMemcpyDefault is only" ] # [ doc = " allowed on systems that support unified virtual addressing." ] # [ doc = "" ] # [ doc = " The memory areas may not overlap. Calling ::cudaMemcpyAsync() with \\p dst and" ] # [ doc = " \\p src pointers that do not match the direction of the copy results in an" ] # [ doc = " undefined behavior." ] # [ doc = "" ] # [ doc = " ::cudaMemcpyAsync() is asynchronous with respect to the host, so the call" ] # [ doc = " may return before the copy is complete. The copy can optionally be" ] # [ doc = " associated to a stream by passing a non-zero \\p stream argument. If \\p kind" ] # [ doc = " is ::cudaMemcpyHostToDevice or ::cudaMemcpyDeviceToHost and the \\p stream is" ] # [ doc = " non-zero, the copy may overlap with operations in other streams." ] # [ doc = "" ] # [ doc = " The device version of this function only handles device to device copies and" ] # [ doc = " cannot be given local or shared pointers." ] # [ doc = "" ] # [ doc = " \\param dst    - Destination memory address" ] # [ doc = " \\param src    - Source memory address" ] # [ doc = " \\param count  - Size in bytes to copy" ] # [ doc = " \\param kind   - Type of transfer" ] # [ doc = " \\param stream - Stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidMemcpyDirection" ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_async" ] # [ doc = " \\note_null_stream" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy, ::cudaMemcpy2D, ::cudaMemcpyToArray," ] # [ doc = " ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray," ] # [ doc = " ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray, ::cudaMemcpyToSymbol," ] # [ doc = " ::cudaMemcpyFromSymbol, ::cudaMemcpy2DAsync," ] # [ doc = " ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync," ] # [ doc = " ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync," ] # [ doc = " ::cudaMemcpyToSymbolAsync, ::cudaMemcpyFromSymbolAsync" ] # [ doc = " ::cuMemcpyAsync," ] # [ doc = " ::cuMemcpyDtoHAsync," ] # [ doc = " ::cuMemcpyHtoDAsync," ] # [ doc = " ::cuMemcpyDtoDAsync" ] pub fn cudaMemcpyAsync ( dst : * mut :: std :: os :: raw :: c_void , src : * const :: std :: os :: raw :: c_void , count : usize , kind : cudaMemcpyKind , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Copies memory between two devices asynchronously." ] # [ doc = "" ] # [ doc = " Copies memory from one device to memory on another device.  \\p dst is the" ] # [ doc = " base device pointer of the destination memory and \\p dstDevice is the" ] # [ doc = " destination device.  \\p src is the base device pointer of the source memory" ] # [ doc = " and \\p srcDevice is the source device.  \\p count specifies the number of bytes" ] # [ doc = " to copy." ] # [ doc = "" ] # [ doc = " Note that this function is asynchronous with respect to the host and all work" ] # [ doc = " on other devices." ] # [ doc = "" ] # [ doc = " \\param dst       - Destination device pointer" ] # [ doc = " \\param dstDevice - Destination device" ] # [ doc = " \\param src       - Source device pointer" ] # [ doc = " \\param srcDevice - Source device" ] # [ doc = " \\param count     - Size of memory copy in bytes" ] # [ doc = " \\param stream    - Stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_async" ] # [ doc = " \\note_null_stream" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy, ::cudaMemcpyPeer, ::cudaMemcpyAsync," ] # [ doc = " ::cudaMemcpy3DPeerAsync," ] # [ doc = " ::cuMemcpyPeerAsync" ] pub fn cudaMemcpyPeerAsync ( dst : * mut :: std :: os :: raw :: c_void , dstDevice : :: std :: os :: raw :: c_int , src : * const :: std :: os :: raw :: c_void , srcDevice : :: std :: os :: raw :: c_int , count : usize , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Copies data between host and device" ] # [ doc = "" ] # [ doc = " Copies a matrix (\\p height rows of \\p width bytes each) from the memory" ] # [ doc = " area pointed to by \\p src to the memory area pointed to by \\p dst, where" ] # [ doc = " \\p kind specifies the direction of the copy, and must be one of" ] # [ doc = " ::cudaMemcpyHostToHost, ::cudaMemcpyHostToDevice, ::cudaMemcpyDeviceToHost," ] # [ doc = " ::cudaMemcpyDeviceToDevice, or ::cudaMemcpyDefault. Passing" ] # [ doc = " ::cudaMemcpyDefault is recommended, in which case the type of transfer is" ] # [ doc = " inferred from the pointer values. However, ::cudaMemcpyDefault is only" ] # [ doc = " allowed on systems that support unified virtual addressing." ] # [ doc = " \\p dpitch and \\p spitch are the widths in memory in bytes of the 2D arrays" ] # [ doc = " pointed to by \\p dst and \\p src, including any padding added to the end of" ] # [ doc = " each row. The memory areas may not overlap. \\p width must not exceed either" ] # [ doc = " \\p dpitch or \\p spitch." ] # [ doc = "" ] # [ doc = " Calling ::cudaMemcpy2DAsync() with \\p dst and \\p src pointers that do not" ] # [ doc = " match the direction of the copy results in an undefined behavior." ] # [ doc = " ::cudaMemcpy2DAsync() returns an error if \\p dpitch or \\p spitch is greater" ] # [ doc = " than the maximum allowed." ] # [ doc = "" ] # [ doc = " ::cudaMemcpy2DAsync() is asynchronous with respect to the host, so" ] # [ doc = " the call may return before the copy is complete. The copy can optionally" ] # [ doc = " be associated to a stream by passing a non-zero \\p stream argument. If" ] # [ doc = " \\p kind is ::cudaMemcpyHostToDevice or ::cudaMemcpyDeviceToHost and" ] # [ doc = " \\p stream is non-zero, the copy may overlap with operations in other" ] # [ doc = " streams." ] # [ doc = "" ] # [ doc = " The device version of this function only handles device to device copies and" ] # [ doc = " cannot be given local or shared pointers." ] # [ doc = "" ] # [ doc = " \\param dst    - Destination memory address" ] # [ doc = " \\param dpitch - Pitch of destination memory" ] # [ doc = " \\param src    - Source memory address" ] # [ doc = " \\param spitch - Pitch of source memory" ] # [ doc = " \\param width  - Width of matrix transfer (columns in bytes)" ] # [ doc = " \\param height - Height of matrix transfer (rows)" ] # [ doc = " \\param kind   - Type of transfer" ] # [ doc = " \\param stream - Stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidPitchValue," ] # [ doc = " ::cudaErrorInvalidMemcpyDirection" ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_async" ] # [ doc = " \\note_null_stream" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy, ::cudaMemcpy2D, ::cudaMemcpyToArray," ] # [ doc = " ::cudaMemcpy2DToArray, ::cudaMemcpyFromArray, ::cudaMemcpy2DFromArray," ] # [ doc = " ::cudaMemcpyArrayToArray, ::cudaMemcpy2DArrayToArray, ::cudaMemcpyToSymbol," ] # [ doc = " ::cudaMemcpyFromSymbol, ::cudaMemcpyAsync," ] # [ doc = " ::cudaMemcpyToArrayAsync, ::cudaMemcpy2DToArrayAsync," ] # [ doc = " ::cudaMemcpyFromArrayAsync, ::cudaMemcpy2DFromArrayAsync," ] # [ doc = " ::cudaMemcpyToSymbolAsync, ::cudaMemcpyFromSymbolAsync," ] # [ doc = " ::cuMemcpy2DAsync" ] pub fn cudaMemcpy2DAsync ( dst : * mut :: std :: os :: raw :: c_void , dpitch : usize , src : * const :: std :: os :: raw :: c_void , spitch : usize , width : usize , height : usize , kind : cudaMemcpyKind , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Initializes or sets device memory to a value" ] # [ doc = "" ] # [ doc = " Fills the first \\p count bytes of the memory area pointed to by \\p devPtr" ] # [ doc = " with the constant byte value \\p value." ] # [ doc = "" ] # [ doc = " Note that this function is asynchronous with respect to the host unless" ] # [ doc = " \\p devPtr refers to pinned host memory." ] # [ doc = "" ] # [ doc = " \\param devPtr - Pointer to device memory" ] # [ doc = " \\param value  - Value to set for each byte of specified memory" ] # [ doc = " \\param count  - Size in bytes to set" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_memset" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cuMemsetD8," ] # [ doc = " ::cuMemsetD16," ] # [ doc = " ::cuMemsetD32" ] pub fn cudaMemset ( devPtr : * mut :: std :: os :: raw :: c_void , value : :: std :: os :: raw :: c_int , count : usize ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Initializes or sets device memory to a value" ] # [ doc = "" ] # [ doc = " Fills the first \\p count bytes of the memory area pointed to by \\p devPtr" ] # [ doc = " with the constant byte value \\p value." ] # [ doc = "" ] # [ doc = " ::cudaMemsetAsync() is asynchronous with respect to the host, so" ] # [ doc = " the call may return before the memset is complete. The operation can optionally" ] # [ doc = " be associated to a stream by passing a non-zero \\p stream argument." ] # [ doc = " If \\p stream is non-zero, the operation may overlap with operations in other streams." ] # [ doc = "" ] # [ doc = " The device version of this function only handles device to device copies and" ] # [ doc = " cannot be given local or shared pointers." ] # [ doc = "" ] # [ doc = " \\param devPtr - Pointer to device memory" ] # [ doc = " \\param value  - Value to set for each byte of specified memory" ] # [ doc = " \\param count  - Size in bytes to set" ] # [ doc = " \\param stream - Stream identifier" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_memset" ] # [ doc = " \\note_null_stream" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemset, ::cudaMemset2D, ::cudaMemset3D," ] # [ doc = " ::cudaMemset2DAsync, ::cudaMemset3DAsync," ] # [ doc = " ::cuMemsetD8Async," ] # [ doc = " ::cuMemsetD16Async," ] # [ doc = " ::cuMemsetD32Async" ] pub fn cudaMemsetAsync ( devPtr : * mut :: std :: os :: raw :: c_void , value : :: std :: os :: raw :: c_int , count : usize , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Prefetches memory to the specified destination device" ] # [ doc = "" ] # [ doc = " Prefetches memory to the specified destination device.  \\p devPtr is the" ] # [ doc = " base device pointer of the memory to be prefetched and \\p dstDevice is the" ] # [ doc = " destination device. \\p count specifies the number of bytes to copy. \\p stream" ] # [ doc = " is the stream in which the operation is enqueued. The memory range must refer" ] # [ doc = " to managed memory allocated via ::cudaMallocManaged or declared via __managed__ variables." ] # [ doc = "" ] # [ doc = " Passing in cudaCpuDeviceId for \\p dstDevice will prefetch the data to host memory. If" ] # [ doc = " \\p dstDevice is a GPU, then the device attribute ::cudaDevAttrConcurrentManagedAccess" ] # [ doc = " must be non-zero. Additionally, \\p stream must be associated with a device that has a" ] # [ doc = " non-zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess." ] # [ doc = "" ] # [ doc = " The start address and end address of the memory range will be rounded down and rounded up" ] # [ doc = " respectively to be aligned to CPU page size before the prefetch operation is enqueued" ] # [ doc = " in the stream." ] # [ doc = "" ] # [ doc = " If no physical memory has been allocated for this region, then this memory region" ] # [ doc = " will be populated and mapped on the destination device. If there\'s insufficient" ] # [ doc = " memory to prefetch the desired region, the Unified Memory driver may evict pages from other" ] # [ doc = " ::cudaMallocManaged allocations to host memory in order to make room. Device memory" ] # [ doc = " allocated using ::cudaMalloc or ::cudaMallocArray will not be evicted." ] # [ doc = "" ] # [ doc = " By default, any mappings to the previous location of the migrated pages are removed and" ] # [ doc = " mappings for the new location are only setup on \\p dstDevice. The exact behavior however" ] # [ doc = " also depends on the settings applied to this memory range via ::cudaMemAdvise as described" ] # [ doc = " below:" ] # [ doc = "" ] # [ doc = " If ::cudaMemAdviseSetReadMostly was set on any subset of this memory range," ] # [ doc = " then that subset will create a read-only copy of the pages on \\p dstDevice." ] # [ doc = "" ] # [ doc = " If ::cudaMemAdviseSetPreferredLocation was called on any subset of this memory" ] # [ doc = " range, then the pages will be migrated to \\p dstDevice even if \\p dstDevice is not the" ] # [ doc = " preferred location of any pages in the memory range." ] # [ doc = "" ] # [ doc = " If ::cudaMemAdviseSetAccessedBy was called on any subset of this memory range," ] # [ doc = " then mappings to those pages from all the appropriate processors are updated to" ] # [ doc = " refer to the new location if establishing such a mapping is possible. Otherwise," ] # [ doc = " those mappings are cleared." ] # [ doc = "" ] # [ doc = " Note that this API is not required for functionality and only serves to improve performance" ] # [ doc = " by allowing the application to migrate data to a suitable location before it is accessed." ] # [ doc = " Memory accesses to this range are always coherent and are allowed even when the data is" ] # [ doc = " actively being migrated." ] # [ doc = "" ] # [ doc = " Note that this function is asynchronous with respect to the host and all work" ] # [ doc = " on other devices." ] # [ doc = "" ] # [ doc = " \\param devPtr    - Pointer to be prefetched" ] # [ doc = " \\param count     - Size in bytes" ] # [ doc = " \\param dstDevice - Destination device to prefetch to" ] # [ doc = " \\param stream    - Stream to enqueue prefetch operation" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_async" ] # [ doc = " \\note_null_stream" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy, ::cudaMemcpyPeer, ::cudaMemcpyAsync," ] # [ doc = " ::cudaMemcpy3DPeerAsync, ::cudaMemAdvise," ] # [ doc = " ::cuMemPrefetchAsync" ] pub fn cudaMemPrefetchAsync ( devPtr : * const :: std :: os :: raw :: c_void , count : usize , dstDevice : :: std :: os :: raw :: c_int , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Advise about the usage of a given memory range" ] # [ doc = "" ] # [ doc = " Advise the Unified Memory subsystem about the usage pattern for the memory range" ] # [ doc = " starting at \\p devPtr with a size of \\p count bytes. The start address and end address of the memory" ] # [ doc = " range will be rounded down and rounded up respectively to be aligned to CPU page size before the" ] # [ doc = " advice is applied. The memory range must refer to managed memory allocated via ::cudaMallocManaged" ] # [ doc = " or declared via __managed__ variables. The memory range could also refer to system-allocated pageable" ] # [ doc = " memory provided it represents a valid, host-accessible region of memory and all additional constraints" ] # [ doc = " imposed by \\p advice as outlined below are also satisfied. Specifying an invalid system-allocated pageable" ] # [ doc = " memory range results in an error being returned." ] # [ doc = "" ] # [ doc = " The \\p advice parameter can take the following values:" ] # [ doc = " - ::cudaMemAdviseSetReadMostly: This implies that the data is mostly going to be read" ] # [ doc = " from and only occasionally written to. Any read accesses from any processor to this region will create a" ] # [ doc = " read-only copy of at least the accessed pages in that processor\'s memory. Additionally, if ::cudaMemPrefetchAsync" ] # [ doc = " is called on this region, it will create a read-only copy of the data on the destination processor." ] # [ doc = " If any processor writes to this region, all copies of the corresponding page will be invalidated" ] # [ doc = " except for the one where the write occurred. The \\p device argument is ignored for this advice." ] # [ doc = " Note that for a page to be read-duplicated, the accessing processor must either be the CPU or a GPU" ] # [ doc = " that has a non-zero value for the device attribute ::cudaDevAttrConcurrentManagedAccess." ] # [ doc = " Also, if a context is created on a device that does not have the device attribute" ] # [ doc = " ::cudaDevAttrConcurrentManagedAccess set, then read-duplication will not occur until" ] # [ doc = " all such contexts are destroyed." ] # [ doc = " If the memory region refers to valid system-allocated pageable memory, then the accessing device must" ] # [ doc = " have a non-zero value for the device attribute ::cudaDevAttrPageableMemoryAccess for a read-only" ] # [ doc = " copy to be created on that device. Note however that if the accessing device also has a non-zero value for the" ] # [ doc = " device attribute ::cudaDevAttrPageableMemoryAccessUsesHostPageTables, then setting this advice" ] # [ doc = " will not create a read-only copy when that device accesses this memory region." ] # [ doc = "" ] # [ doc = " - ::cudaMemAdviceUnsetReadMostly: Undoes the effect of ::cudaMemAdviceReadMostly and also prevents the" ] # [ doc = " Unified Memory driver from attempting heuristic read-duplication on the memory range. Any read-duplicated" ] # [ doc = " copies of the data will be collapsed into a single copy. The location for the collapsed" ] # [ doc = " copy will be the preferred location if the page has a preferred location and one of the read-duplicated" ] # [ doc = " copies was resident at that location. Otherwise, the location chosen is arbitrary." ] # [ doc = "" ] # [ doc = " - ::cudaMemAdviseSetPreferredLocation: This advice sets the preferred location for the" ] # [ doc = " data to be the memory belonging to \\p device. Passing in cudaCpuDeviceId for \\p device sets the" ] # [ doc = " preferred location as host memory. If \\p device is a GPU, then it must have a non-zero value for the" ] # [ doc = " device attribute ::cudaDevAttrConcurrentManagedAccess. Setting the preferred location" ] # [ doc = " does not cause data to migrate to that location immediately. Instead, it guides the migration policy" ] # [ doc = " when a fault occurs on that memory region. If the data is already in its preferred location and the" ] # [ doc = " faulting processor can establish a mapping without requiring the data to be migrated, then" ] # [ doc = " data migration will be avoided. On the other hand, if the data is not in its preferred location" ] # [ doc = " or if a direct mapping cannot be established, then it will be migrated to the processor accessing" ] # [ doc = " it. It is important to note that setting the preferred location does not prevent data prefetching" ] # [ doc = " done using ::cudaMemPrefetchAsync." ] # [ doc = " Having a preferred location can override the page thrash detection and resolution logic in the Unified" ] # [ doc = " Memory driver. Normally, if a page is detected to be constantly thrashing between for example host and device" ] # [ doc = " memory, the page may eventually be pinned to host memory by the Unified Memory driver. But" ] # [ doc = " if the preferred location is set as device memory, then the page will continue to thrash indefinitely." ] # [ doc = " If ::cudaMemAdviseSetReadMostly is also set on this memory region or any subset of it, then the" ] # [ doc = " policies associated with that advice will override the policies of this advice, unless read accesses from" ] # [ doc = " \\p device will not result in a read-only copy being created on that device as outlined in description for" ] # [ doc = " the advice ::cudaMemAdviseSetReadMostly." ] # [ doc = " If the memory region refers to valid system-allocated pageable memory, then \\p device must have a non-zero" ] # [ doc = " value for the device attribute ::cudaDevAttrPageableMemoryAccess. Additionally, if \\p device has" ] # [ doc = " a non-zero value for the device attribute ::cudaDevAttrPageableMemoryAccessUsesHostPageTables," ] # [ doc = " then this call has no effect. Note however that this behavior may change in the future." ] # [ doc = "" ] # [ doc = " - ::cudaMemAdviseUnsetPreferredLocation: Undoes the effect of ::cudaMemAdviseSetPreferredLocation" ] # [ doc = " and changes the preferred location to none." ] # [ doc = "" ] # [ doc = " - ::cudaMemAdviseSetAccessedBy: This advice implies that the data will be accessed by \\p device." ] # [ doc = " Passing in ::cudaCpuDeviceId for \\p device will set the advice for the CPU. If \\p device is a GPU, then" ] # [ doc = " the device attribute ::cudaDevAttrConcurrentManagedAccess must be non-zero." ] # [ doc = " This advice does not cause data migration and has no impact on the location of the data per se. Instead," ] # [ doc = " it causes the data to always be mapped in the specified processor\'s page tables, as long as the" ] # [ doc = " location of the data permits a mapping to be established. If the data gets migrated for any reason," ] # [ doc = " the mappings are updated accordingly." ] # [ doc = " This advice is recommended in scenarios where data locality is not important, but avoiding faults is." ] # [ doc = " Consider for example a system containing multiple GPUs with peer-to-peer access enabled, where the" ] # [ doc = " data located on one GPU is occasionally accessed by peer GPUs. In such scenarios, migrating data" ] # [ doc = " over to the other GPUs is not as important because the accesses are infrequent and the overhead of" ] # [ doc = " migration may be too high. But preventing faults can still help improve performance, and so having" ] # [ doc = " a mapping set up in advance is useful. Note that on CPU access of this data, the data may be migrated" ] # [ doc = " to host memory because the CPU typically cannot access device memory directly. Any GPU that had the" ] # [ doc = " ::cudaMemAdviceSetAccessedBy flag set for this data will now have its mapping updated to point to the" ] # [ doc = " page in host memory." ] # [ doc = " If ::cudaMemAdviseSetReadMostly is also set on this memory region or any subset of it, then the" ] # [ doc = " policies associated with that advice will override the policies of this advice. Additionally, if the" ] # [ doc = " preferred location of this memory region or any subset of it is also \\p device, then the policies" ] # [ doc = " associated with ::cudaMemAdviseSetPreferredLocation will override the policies of this advice." ] # [ doc = " If the memory region refers to valid system-allocated pageable memory, then \\p device must have a non-zero" ] # [ doc = " value for the device attribute ::cudaDevAttrPageableMemoryAccess. Additionally, if \\p device has" ] # [ doc = " a non-zero value for the device attribute ::cudaDevAttrPageableMemoryAccessUsesHostPageTables," ] # [ doc = " then this call has no effect." ] # [ doc = "" ] # [ doc = " - ::cudaMemAdviseUnsetAccessedBy: Undoes the effect of ::cudaMemAdviseSetAccessedBy. Any mappings to" ] # [ doc = " the data from \\p device may be removed at any time causing accesses to result in non-fatal page faults." ] # [ doc = " If the memory region refers to valid system-allocated pageable memory, then \\p device must have a non-zero" ] # [ doc = " value for the device attribute ::cudaDevAttrPageableMemoryAccess. Additionally, if \\p device has" ] # [ doc = " a non-zero value for the device attribute ::cudaDevAttrPageableMemoryAccessUsesHostPageTables," ] # [ doc = " then this call has no effect." ] # [ doc = "" ] # [ doc = " \\param devPtr - Pointer to memory to set the advice for" ] # [ doc = " \\param count  - Size in bytes of the memory range" ] # [ doc = " \\param advice - Advice to be applied for the specified memory range" ] # [ doc = " \\param device - Device to apply the advice for" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_async" ] # [ doc = " \\note_null_stream" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemcpy, ::cudaMemcpyPeer, ::cudaMemcpyAsync," ] # [ doc = " ::cudaMemcpy3DPeerAsync, ::cudaMemPrefetchAsync," ] # [ doc = " ::cuMemAdvise" ] pub fn cudaMemAdvise ( devPtr : * const :: std :: os :: raw :: c_void , count : usize , advice : cudaMemoryAdvise , device : :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Query an attribute of a given memory range" ] # [ doc = "" ] # [ doc = " Query an attribute about the memory range starting at \\p devPtr with a size of \\p count bytes. The" ] # [ doc = " memory range must refer to managed memory allocated via ::cudaMallocManaged or declared via" ] # [ doc = " __managed__ variables." ] # [ doc = "" ] # [ doc = " The \\p attribute parameter can take the following values:" ] # [ doc = " - ::cudaMemRangeAttributeReadMostly: If this attribute is specified, \\p data will be interpreted" ] # [ doc = " as a 32-bit integer, and \\p dataSize must be 4. The result returned will be 1 if all pages in the given" ] # [ doc = " memory range have read-duplication enabled, or 0 otherwise." ] # [ doc = " - ::cudaMemRangeAttributePreferredLocation: If this attribute is specified, \\p data will be" ] # [ doc = " interpreted as a 32-bit integer, and \\p dataSize must be 4. The result returned will be a GPU device" ] # [ doc = " id if all pages in the memory range have that GPU as their preferred location, or it will be cudaCpuDeviceId" ] # [ doc = " if all pages in the memory range have the CPU as their preferred location, or it will be cudaInvalidDeviceId" ] # [ doc = " if either all the pages don\'t have the same preferred location or some of the pages don\'t have a" ] # [ doc = " preferred location at all. Note that the actual location of the pages in the memory range at the time of" ] # [ doc = " the query may be different from the preferred location." ] # [ doc = " - ::cudaMemRangeAttributeAccessedBy: If this attribute is specified, \\p data will be interpreted" ] # [ doc = " as an array of 32-bit integers, and \\p dataSize must be a non-zero multiple of 4. The result returned" ] # [ doc = " will be a list of device ids that had ::cudaMemAdviceSetAccessedBy set for that entire memory range." ] # [ doc = " If any device does not have that advice set for the entire memory range, that device will not be included." ] # [ doc = " If \\p data is larger than the number of devices that have that advice set for that memory range," ] # [ doc = " cudaInvalidDeviceId will be returned in all the extra space provided. For ex., if \\p dataSize is 12" ] # [ doc = " (i.e. \\p data has 3 elements) and only device 0 has the advice set, then the result returned will be" ] # [ doc = " { 0, cudaInvalidDeviceId, cudaInvalidDeviceId }. If \\p data is smaller than the number of devices that have" ] # [ doc = " that advice set, then only as many devices will be returned as can fit in the array. There is no" ] # [ doc = " guarantee on which specific devices will be returned, however." ] # [ doc = " - ::cudaMemRangeAttributeLastPrefetchLocation: If this attribute is specified, \\p data will be" ] # [ doc = " interpreted as a 32-bit integer, and \\p dataSize must be 4. The result returned will be the last location" ] # [ doc = " to which all pages in the memory range were prefetched explicitly via ::cudaMemPrefetchAsync. This will either be" ] # [ doc = " a GPU id or cudaCpuDeviceId depending on whether the last location for prefetch was a GPU or the CPU" ] # [ doc = " respectively. If any page in the memory range was never explicitly prefetched or if all pages were not" ] # [ doc = " prefetched to the same location, cudaInvalidDeviceId will be returned. Note that this simply returns the" ] # [ doc = " last location that the applicaton requested to prefetch the memory range to. It gives no indication as to" ] # [ doc = " whether the prefetch operation to that location has completed or even begun." ] # [ doc = "" ] # [ doc = " \\param data      - A pointers to a memory location where the result" ] # [ doc = "                    of each attribute query will be written to." ] # [ doc = " \\param dataSize  - Array containing the size of data" ] # [ doc = " \\param attribute - The attribute to query" ] # [ doc = " \\param devPtr    - Start of the range to query" ] # [ doc = " \\param count     - Size of the range to query" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = " \\note_async" ] # [ doc = " \\note_null_stream" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemRangeGetAttributes, ::cudaMemPrefetchAsync," ] # [ doc = " ::cudaMemAdvise," ] # [ doc = " ::cuMemRangeGetAttribute" ] pub fn cudaMemRangeGetAttribute ( data : * mut :: std :: os :: raw :: c_void , dataSize : usize , attribute : cudaMemRangeAttribute , devPtr : * const :: std :: os :: raw :: c_void , count : usize ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Query attributes of a given memory range." ] # [ doc = "" ] # [ doc = " Query attributes of the memory range starting at \\p devPtr with a size of \\p count bytes. The" ] # [ doc = " memory range must refer to managed memory allocated via ::cudaMallocManaged or declared via" ] # [ doc = " __managed__ variables. The \\p attributes array will be interpreted to have \\p numAttributes" ] # [ doc = " entries. The \\p dataSizes array will also be interpreted to have \\p numAttributes entries." ] # [ doc = " The results of the query will be stored in \\p data." ] # [ doc = "" ] # [ doc = " The list of supported attributes are given below. Please refer to ::cudaMemRangeGetAttribute for" ] # [ doc = " attribute descriptions and restrictions." ] # [ doc = "" ] # [ doc = " - ::cudaMemRangeAttributeReadMostly" ] # [ doc = " - ::cudaMemRangeAttributePreferredLocation" ] # [ doc = " - ::cudaMemRangeAttributeAccessedBy" ] # [ doc = " - ::cudaMemRangeAttributeLastPrefetchLocation" ] # [ doc = "" ] # [ doc = " \\param data          - A two-dimensional array containing pointers to memory" ] # [ doc = "                        locations where the result of each attribute query will be written to." ] # [ doc = " \\param dataSizes     - Array containing the sizes of each result" ] # [ doc = " \\param attributes    - An array of attributes to query" ] # [ doc = "                        (numAttributes and the number of attributes in this array should match)" ] # [ doc = " \\param numAttributes - Number of attributes to query" ] # [ doc = " \\param devPtr        - Start of the range to query" ] # [ doc = " \\param count         - Size of the range to query" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaMemRangeGetAttribute, ::cudaMemAdvise" ] # [ doc = " ::cudaMemPrefetchAsync," ] # [ doc = " ::cuMemRangeGetAttributes" ] pub fn cudaMemRangeGetAttributes ( data : * mut * mut :: std :: os :: raw :: c_void , dataSizes : * mut usize , attributes : * mut cudaMemRangeAttribute , numAttributes : usize , devPtr : * const :: std :: os :: raw :: c_void , count : usize ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Queries if a device may directly access a peer device\'s memory." ] # [ doc = "" ] # [ doc = " Returns in \\p *canAccessPeer a value of 1 if device \\p device is capable of" ] # [ doc = " directly accessing memory from \\p peerDevice and 0 otherwise.  If direct" ] # [ doc = " access of \\p peerDevice from \\p device is possible, then access may be" ] # [ doc = " enabled by calling ::cudaDeviceEnablePeerAccess()." ] # [ doc = "" ] # [ doc = " \\param canAccessPeer - Returned access capability" ] # [ doc = " \\param device        - Device from which allocations on \\p peerDevice are to" ] # [ doc = "                        be directly accessed." ] # [ doc = " \\param peerDevice    - Device on which the allocations to be directly accessed" ] # [ doc = "                        by \\p device reside." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaDeviceEnablePeerAccess," ] # [ doc = " ::cudaDeviceDisablePeerAccess," ] # [ doc = " ::cuDeviceCanAccessPeer" ] pub fn cudaDeviceCanAccessPeer ( canAccessPeer : * mut :: std :: os :: raw :: c_int , device : :: std :: os :: raw :: c_int , peerDevice : :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Enables direct access to memory allocations on a peer device." ] # [ doc = "" ] # [ doc = " On success, all allocations from \\p peerDevice will immediately be accessible by" ] # [ doc = " the current device.  They will remain accessible until access is explicitly" ] # [ doc = " disabled using ::cudaDeviceDisablePeerAccess() or either device is reset using" ] # [ doc = " ::cudaDeviceReset()." ] # [ doc = "" ] # [ doc = " Note that access granted by this call is unidirectional and that in order to access" ] # [ doc = " memory on the current device from \\p peerDevice, a separate symmetric call" ] # [ doc = " to ::cudaDeviceEnablePeerAccess() is required." ] # [ doc = "" ] # [ doc = " Each device can support a system-wide maximum of eight peer connections." ] # [ doc = "" ] # [ doc = " Peer access is not supported in 32 bit applications." ] # [ doc = "" ] # [ doc = " Returns ::cudaErrorInvalidDevice if ::cudaDeviceCanAccessPeer() indicates" ] # [ doc = " that the current device cannot directly access memory from \\p peerDevice." ] # [ doc = "" ] # [ doc = " Returns ::cudaErrorPeerAccessAlreadyEnabled if direct access of" ] # [ doc = " \\p peerDevice from the current device has already been enabled." ] # [ doc = "" ] # [ doc = " Returns ::cudaErrorInvalidValue if \\p flags is not 0." ] # [ doc = "" ] # [ doc = " \\param peerDevice  - Peer device to enable direct access to from the current device" ] # [ doc = " \\param flags       - Reserved for future use and must be set to 0" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidDevice," ] # [ doc = " ::cudaErrorPeerAccessAlreadyEnabled," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaDeviceCanAccessPeer," ] # [ doc = " ::cudaDeviceDisablePeerAccess," ] # [ doc = " ::cuCtxEnablePeerAccess" ] pub fn cudaDeviceEnablePeerAccess ( peerDevice : :: std :: os :: raw :: c_int , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Disables direct access to memory allocations on a peer device." ] # [ doc = "" ] # [ doc = " Returns ::cudaErrorPeerAccessNotEnabled if direct access to memory on" ] # [ doc = " \\p peerDevice has not yet been enabled from the current device." ] # [ doc = "" ] # [ doc = " \\param peerDevice - Peer device to disable direct access to" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorPeerAccessNotEnabled," ] # [ doc = " ::cudaErrorInvalidDevice" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa ::cudaDeviceCanAccessPeer," ] # [ doc = " ::cudaDeviceEnablePeerAccess," ] # [ doc = " ::cuCtxDisablePeerAccess" ] pub fn cudaDeviceDisablePeerAccess ( peerDevice : :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Unregisters a graphics resource for access by CUDA" ] # [ doc = "" ] # [ doc = " Unregisters the graphics resource \\p resource so it is not accessible by" ] # [ doc = " CUDA unless registered again." ] # [ doc = "" ] # [ doc = " If \\p resource is invalid then ::cudaErrorInvalidResourceHandle is" ] # [ doc = " returned." ] # [ doc = "" ] # [ doc = " \\param resource - Resource to unregister" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorUnknown" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaGraphicsD3D9RegisterResource," ] # [ doc = " ::cudaGraphicsD3D10RegisterResource," ] # [ doc = " ::cudaGraphicsD3D11RegisterResource," ] # [ doc = " ::cudaGraphicsGLRegisterBuffer," ] # [ doc = " ::cudaGraphicsGLRegisterImage," ] # [ doc = " ::cuGraphicsUnregisterResource" ] pub fn cudaGraphicsUnregisterResource ( resource : cudaGraphicsResource_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Set usage flags for mapping a graphics resource" ] # [ doc = "" ] # [ doc = " Set \\p flags for mapping the graphics resource \\p resource." ] # [ doc = "" ] # [ doc = " Changes to \\p flags will take effect the next time \\p resource is mapped." ] # [ doc = " The \\p flags argument may be any of the following:" ] # [ doc = " - ::cudaGraphicsMapFlagsNone: Specifies no hints about how \\p resource will" ] # [ doc = "     be used. It is therefore assumed that CUDA may read from or write to \\p resource." ] # [ doc = " - ::cudaGraphicsMapFlagsReadOnly: Specifies that CUDA will not write to \\p resource." ] # [ doc = " - ::cudaGraphicsMapFlagsWriteDiscard: Specifies CUDA will not read from \\p resource and will" ] # [ doc = "   write over the entire contents of \\p resource, so none of the data" ] # [ doc = "   previously stored in \\p resource will be preserved." ] # [ doc = "" ] # [ doc = " If \\p resource is presently mapped for access by CUDA then ::cudaErrorUnknown is returned." ] # [ doc = " If \\p flags is not one of the above values then ::cudaErrorInvalidValue is returned." ] # [ doc = "" ] # [ doc = " \\param resource - Registered resource to set flags for" ] # [ doc = " \\param flags    - Parameters for resource mapping" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorUnknown," ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaGraphicsMapResources," ] # [ doc = " ::cuGraphicsResourceSetMapFlags" ] pub fn cudaGraphicsResourceSetMapFlags ( resource : cudaGraphicsResource_t , flags : :: std :: os :: raw :: c_uint ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Map graphics resources for access by CUDA" ] # [ doc = "" ] # [ doc = " Maps the \\p count graphics resources in \\p resources for access by CUDA." ] # [ doc = "" ] # [ doc = " The resources in \\p resources may be accessed by CUDA until they" ] # [ doc = " are unmapped. The graphics API from which \\p resources were registered" ] # [ doc = " should not access any resources while they are mapped by CUDA. If an" ] # [ doc = " application does so, the results are undefined." ] # [ doc = "" ] # [ doc = " This function provides the synchronization guarantee that any graphics calls" ] # [ doc = " issued before ::cudaGraphicsMapResources() will complete before any subsequent CUDA" ] # [ doc = " work issued in \\p stream begins." ] # [ doc = "" ] # [ doc = " If \\p resources contains any duplicate entries then ::cudaErrorInvalidResourceHandle" ] # [ doc = " is returned. If any of \\p resources are presently mapped for access by" ] # [ doc = " CUDA then ::cudaErrorUnknown is returned." ] # [ doc = "" ] # [ doc = " \\param count     - Number of resources to map" ] # [ doc = " \\param resources - Resources to map for CUDA" ] # [ doc = " \\param stream    - Stream for synchronization" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorUnknown" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaGraphicsResourceGetMappedPointer," ] # [ doc = " ::cudaGraphicsSubResourceGetMappedArray," ] # [ doc = " ::cudaGraphicsUnmapResources," ] # [ doc = " ::cuGraphicsMapResources" ] pub fn cudaGraphicsMapResources ( count : :: std :: os :: raw :: c_int , resources : * mut cudaGraphicsResource_t , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Unmap graphics resources." ] # [ doc = "" ] # [ doc = " Unmaps the \\p count graphics resources in \\p resources." ] # [ doc = "" ] # [ doc = " Once unmapped, the resources in \\p resources may not be accessed by CUDA" ] # [ doc = " until they are mapped again." ] # [ doc = "" ] # [ doc = " This function provides the synchronization guarantee that any CUDA work issued" ] # [ doc = " in \\p stream before ::cudaGraphicsUnmapResources() will complete before any" ] # [ doc = " subsequently issued graphics work begins." ] # [ doc = "" ] # [ doc = " If \\p resources contains any duplicate entries then ::cudaErrorInvalidResourceHandle" ] # [ doc = " is returned. If any of \\p resources are not presently mapped for access by" ] # [ doc = " CUDA then ::cudaErrorUnknown is returned." ] # [ doc = "" ] # [ doc = " \\param count     - Number of resources to unmap" ] # [ doc = " \\param resources - Resources to unmap" ] # [ doc = " \\param stream    - Stream for synchronization" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorUnknown" ] # [ doc = " \\note_null_stream" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaGraphicsMapResources," ] # [ doc = " ::cuGraphicsUnmapResources" ] pub fn cudaGraphicsUnmapResources ( count : :: std :: os :: raw :: c_int , resources : * mut cudaGraphicsResource_t , stream : cudaStream_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Get an device pointer through which to access a mapped graphics resource." ] # [ doc = "" ] # [ doc = " Returns in \\p *devPtr a pointer through which the mapped graphics resource" ] # [ doc = " \\p resource may be accessed." ] # [ doc = " Returns in \\p *size the size of the memory in bytes which may be accessed from that pointer." ] # [ doc = " The value set in \\p devPtr may change every time that \\p resource is mapped." ] # [ doc = "" ] # [ doc = " If \\p resource is not a buffer then it cannot be accessed via a pointer and" ] # [ doc = " ::cudaErrorUnknown is returned." ] # [ doc = " If \\p resource is not mapped then ::cudaErrorUnknown is returned." ] # [ doc = " *" ] # [ doc = " \\param devPtr     - Returned pointer through which \\p resource may be accessed" ] # [ doc = " \\param size       - Returned size of the buffer accessible starting at \\p *devPtr" ] # [ doc = " \\param resource   - Mapped resource to access" ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue," ] # [ doc = " ::cudaErrorInvalidResourceHandle," ] # [ doc = " ::cudaErrorUnknown" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaGraphicsMapResources," ] # [ doc = " ::cudaGraphicsSubResourceGetMappedArray," ] # [ doc = " ::cuGraphicsResourceGetMappedPointer" ] pub fn cudaGraphicsResourceGetMappedPointer ( devPtr : * mut * mut :: std :: os :: raw :: c_void , size : * mut usize , resource : cudaGraphicsResource_t ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Returns the CUDA driver version" ] # [ doc = "" ] # [ doc = " Returns in \\p *driverVersion the version number of the installed CUDA" ] # [ doc = " driver. If no driver is installed, then 0 is returned as the driver" ] # [ doc = " version (via \\p driverVersion). This function automatically returns" ] # [ doc = " ::cudaErrorInvalidValue if the \\p driverVersion argument is NULL." ] # [ doc = "" ] # [ doc = " \\param driverVersion - Returns the CUDA driver version." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = " \\notefnerr" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaRuntimeGetVersion," ] # [ doc = " ::cuDriverGetVersion" ] pub fn cudaDriverGetVersion ( driverVersion : * mut :: std :: os :: raw :: c_int ) -> cudaError_t ; } extern "C" { # [ doc = " \\brief Returns the CUDA Runtime version" ] # [ doc = "" ] # [ doc = " Returns in \\p *runtimeVersion the version number of the installed CUDA" ] # [ doc = " Runtime. This function automatically returns ::cudaErrorInvalidValue if" ] # [ doc = " the \\p runtimeVersion argument is NULL." ] # [ doc = "" ] # [ doc = " \\param runtimeVersion - Returns the CUDA Runtime version." ] # [ doc = "" ] # [ doc = " \\return" ] # [ doc = " ::cudaSuccess," ] # [ doc = " ::cudaErrorInvalidValue" ] # [ doc = "" ] # [ doc = " \\sa" ] # [ doc = " ::cudaDriverGetVersion," ] # [ doc = " ::cuDriverGetVersion" ] pub fn cudaRuntimeGetVersion ( runtimeVersion : * mut :: std :: os :: raw :: c_int ) -> cudaError_t ; }